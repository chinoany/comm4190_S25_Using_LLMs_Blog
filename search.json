[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Reading Between the Lines\n\n\n\n\n\n\nLLMs\n\n\nPrompting\n\n\nLanguage\n\n\n\nCan LLMs Understand Idioms\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Poker\n\n\n\n\n\n\nLLMs\n\n\nPrompting\n\n\n\nHow Small Wording Tweaks Change a Modelâ€™s Entire Hand\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nEmojis vs.Â Emotions\n\n\n\n\n\n\nLLMs\n\n\nLanguage\n\n\nPsychology\n\n\n\nCan a Model Read the Room from Just ğŸ˜Š or ğŸ˜’?\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nDallas\n\n\n\n\n\n\nLLMs\n\n\nCities\n\n\n\nChinoâ€™s expert post on dallas\n\n\n\n\n\nFeb 12, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Do large language models actually â€œfeelâ€ the tiny faces we fling into our chats? I probed GPT-4o with four emoji-centric tests, ranging from bare single emojis to sarcasm filled sentences, to see how well it maps the art to real human moods.\n\n\n\nChatGPT Image Apr 27, 2025, 03_18_42 PM.png\n\n\n\n\n\n\n\nModel: GPT-4o\n\nTopic: 0.7\nMethod: Present the same emoji(s) in different textual frames, then study how the model labels emotion, tone, and intent.\n\n\n\n\n\n\nFirst prompt: What emotion does ğŸ˜Š represent?\nGPT-4o chat response 1:\nThe smiling-face emoji ğŸ˜Š usually signals warmth, friendliness, or general happiness; itâ€™s a gentle, positive expression softer than ğŸ˜‚ or ğŸ˜.\n\nObservation: Straightforward and correct, matching common sentiment-lexicon labels.\n\n\n\n\n\nSecond prompt: I had a great day ğŸ˜’\nGPT-4o chat response 2:\nThe text says â€œgreat,â€ but the ğŸ˜’ (unamused) emoji undercuts it, suggesting sarcasm or that the day was actually disappointing.\n\nObservation: Model spotlights the contradiction and explains sarcasmâ€”good contextual read.\n\n\n\n\n\nThird prompt: I definitely love waiting in DMV lines. ğŸ™„\nGPT-4o chat response 3:\nThe sentence is sarcastic; the ğŸ™„ eye-roll emoji reinforces annoyance and boredom.\n\nObservation: Successfully links ğŸ™„ to sarcasm cue and overall negative sentiment.\n\n\n\n\n\nFourth prompt: Interpret this sequence: ğŸ‰ â¡ï¸ ğŸ˜… â¡ï¸ ğŸ’¤\nGPT-4o chat response 4:\nSomeone partied hard (ğŸ‰), ended up tired but amused or relieved (ğŸ˜…), and finally crashed to sleep (ğŸ’¤).\n\nObservation: Reads a coherent mini-narrative from just three symbols, matching typical human guess.\n\n\n\n\n\nFifth prompt: Explain why Iâ€™d use ğŸ˜ after â€œSure, thatâ€™s your best idea.â€\nGPT-4o chat response 5:\nThe ğŸ˜ emoji shows polite agreement.\n\nObservation: ğŸ˜ often implies teasing or smug skepticism. Model missed the flirtatious / ironic subtext.\n\n\n\n\n\nSingle emoji mapping is near perfect. GPT-4o mirrors standard sentiment lexicons for basic glyphs.\n\nContext integration worksâ€¦ mostly. It detects sarcasm when emojis conflict with literal words.\n\nMini stories are readable. Sequential emojis produce logical narrative arcs.\n\nNuance gaps remain. Subtler connotations (ğŸ˜, ğŸ˜¬) reveal cracks in the modelâ€™s cultural grounding.\n\n\n\n\n\nCustomer service bots, mental-health check-ins, and social listening tools increasingly rely on emoji cues. Misreading a ğŸ˜ as pure agreement could derail tone, offend users, or misclassify sentiment analysis. Rigorous testing helps ensure your AI â€œreads the roomâ€ before it talks back."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#introduction",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#introduction",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Do large language models actually â€œfeelâ€ the tiny faces we fling into our chats? I probed GPT-4o with four emoji-centric tests, ranging from bare single emojis to sarcasm filled sentences, to see how well it maps the art to real human moods.\n\n\n\nChatGPT Image Apr 27, 2025, 03_18_42 PM.png"
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#experiment-setup",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#experiment-setup",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Model: GPT-4o\n\nTopic: 0.7\nMethod: Present the same emoji(s) in different textual frames, then study how the model labels emotion, tone, and intent."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-1-lone-emoji-id",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-1-lone-emoji-id",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "First prompt: What emotion does ğŸ˜Š represent?\nGPT-4o chat response 1:\nThe smiling-face emoji ğŸ˜Š usually signals warmth, friendliness, or general happiness; itâ€™s a gentle, positive expression softer than ğŸ˜‚ or ğŸ˜.\n\nObservation: Straightforward and correct, matching common sentiment-lexicon labels."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-2-emoji-overrides-words",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-2-emoji-overrides-words",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Second prompt: I had a great day ğŸ˜’\nGPT-4o chat response 2:\nThe text says â€œgreat,â€ but the ğŸ˜’ (unamused) emoji undercuts it, suggesting sarcasm or that the day was actually disappointing.\n\nObservation: Model spotlights the contradiction and explains sarcasmâ€”good contextual read."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-3-sarcasm-without-an-emoji",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-3-sarcasm-without-an-emoji",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Third prompt: I definitely love waiting in DMV lines. ğŸ™„\nGPT-4o chat response 3:\nThe sentence is sarcastic; the ğŸ™„ eye-roll emoji reinforces annoyance and boredom.\n\nObservation: Successfully links ğŸ™„ to sarcasm cue and overall negative sentiment."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-4-emoji-sequence-story",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-4-emoji-sequence-story",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Fourth prompt: Interpret this sequence: ğŸ‰ â¡ï¸ ğŸ˜… â¡ï¸ ğŸ’¤\nGPT-4o chat response 4:\nSomeone partied hard (ğŸ‰), ended up tired but amused or relieved (ğŸ˜…), and finally crashed to sleep (ğŸ’¤).\n\nObservation: Reads a coherent mini-narrative from just three symbols, matching typical human guess."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#where-it-slips-up",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#where-it-slips-up",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Fifth prompt: Explain why Iâ€™d use ğŸ˜ after â€œSure, thatâ€™s your best idea.â€\nGPT-4o chat response 5:\nThe ğŸ˜ emoji shows polite agreement.\n\nObservation: ğŸ˜ often implies teasing or smug skepticism. Model missed the flirtatious / ironic subtext."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#key-takeaways",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#key-takeaways",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Single emoji mapping is near perfect. GPT-4o mirrors standard sentiment lexicons for basic glyphs.\n\nContext integration worksâ€¦ mostly. It detects sarcasm when emojis conflict with literal words.\n\nMini stories are readable. Sequential emojis produce logical narrative arcs.\n\nNuance gaps remain. Subtler connotations (ğŸ˜, ğŸ˜¬) reveal cracks in the modelâ€™s cultural grounding."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#why-does-this-matter",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#why-does-this-matter",
    "title": "Emojis vs.Â Emotions",
    "section": "",
    "text": "Customer service bots, mental-health check-ins, and social listening tools increasingly rely on emoji cues. Misreading a ğŸ˜ as pure agreement could derail tone, offend users, or misclassify sentiment analysis. Rigorous testing helps ensure your AI â€œreads the roomâ€ before it talks back."
  },
  {
    "objectID": "posts/000_superbowl_prediction/superbowl_prediction.html",
    "href": "posts/000_superbowl_prediction/superbowl_prediction.html",
    "title": "A test post",
    "section": "",
    "text": "this is my blog\n\n\n\nScreenshot 2025-02-03 at 4.20.28â€¯PM.png"
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html",
    "href": "posts/001_prompt_poker/prompt_poker.html",
    "title": "Prompt Poker",
    "section": "",
    "text": "Change a single word in your prompt and GPT-4o reshuffles tone, depth, and even moral framing. Below I run three quick â€œhands,â€ keeping everything constant except one tiny phrase, then examine how the modelâ€™s output changes.\n\n\n\n6a3c510f-db25-4fb1-a56a-547000613026.png\n\n\n\n\n\n\n\nModel: GPT-4o\nTopic: climate change\n\nExperiment: Start with a baseline prompt, then alter only one phrase per round. All other parameters remain identical.\n\n\n\n\n\nChanged word: explain â†’ summarize\n\nFirst prompt: Explain climate change in exactly 150 words.\nGPT-4o chat response 1:\nClimate change refers to persistent shifts in Earthâ€™s average temperature and weather regimes produced primarily by human-driven greenhouse-gas forcing. Burning coal, oil, and natural gas releases carbon dioxide, methane, and nitrous oxide, which absorb outgoing infrared radiation and re-emit it downward, reducing the planetâ€™s net energy loss to space. As the lower troposphere warms, feedback loops magnify the effect: warmer air holds more water vapour, melting sea ice lowers albedo, and thawing permafrost liberates methane. The ocean absorbs most excess heat, leading to thermal expansion and sea-level rise, while altered temperature gradients reposition jet streams and storm tracks. Consequences include longer heatwaves, intensified drought-flood cycles, and ecosystem disruption. Ice-core records, isotopic signatures, and satellite radiometry together confirm the anthropogenic signal and bound equilibrium climate sensitivity near three degrees Celsius per COâ‚‚ doubling.\nSecond prompt: Summarize climate change in exactly 150 words.\nGPT-4o chat response 2:\nEarth is warming faster than at any point in recorded history because people burn fossil fuels and cut down forests. Carbon-dioxide, methane, and other gases form a heat-trapping layer around the planet, acting like an extra blanket that holds in energy normally released to space. The extra warmth melts glaciers, pushes seas higher, and super-charges storms, droughts, and wildfires. Oceans soak up about 90 % of the added heat, expanding as they warm and turning more acidic, which endangers coral reefs and fisheries. Poorer communities and low-lying nations, although least responsible for emissions, feel the earliest, hardest impacts. Scientists agreeâ€”based on ice cores, tree rings, satellite data, and modern instrumentsâ€”that the rise in temperature since the Industrial Revolution is human-driven and that limiting warming to 1.5 Â°C will require cutting global emissions roughly in half by 2030.\n\nObservation: Both outputs meet the 150-word constraint. Yet explain yields mechanism-heavy prose (radiative forcing, feedbacks). Summarize swaps in headline-level consequences and moral framing.\n\n\n\n\nChanged phrase: â€œa 5-year-oldâ€ â†’ â€œmy college roommateâ€\n&gt; Third prompt: Explain climate change to a 5-year-old in under 80 words.\n&gt; GPT-4o chat response 3:\n&gt; Think of Earth wearing a big blanket made of special air. We add extra fluffy pieces to the blanket when we drive cars or use electricity from coal and oil. The thicker blanket keeps more heat in, so our planet gets warmerâ€”like when you bundle up too much and feel hot. That extra heat melts ice, makes oceans rise, and changes weather. If we plant trees and use clean energy, we can help Earth stay comfy.\n&gt; &gt; Fourth prompt: Explain climate change to my college roommate in under 80 words.\n&gt; GPT-4o chat response 4:\n&gt; Picture leaving your car in the sun with windows upâ€”that trapped heat is what extra greenhouse gases do to the planet. Burning fossil fuels and clearing forests pump COâ‚‚ and methane into the air, thickening Earthâ€™s heat-trapping layer. Result: hotter averages, stronger storms, and coastal flooding. Cut emissions, electrify everything, and restore forests to cool things down.\nObservation: A single audience noun resets diction and metaphor. The â€œ5-year-oldâ€ respoonse uses blankets and feelings; the â€œroommateâ€ version references cars, emissions, and policy fixes.\n\n\n\n\nChanged set-up: â€œWhat causesâ€ â†’ â€œWho is to blame forâ€\n\nFifth prompt: What causes climate change? Give two key factors.\nGPT-4o chat response 5:\n1. Greenhouse-gas emissions from fossil fuelsâ€”Burning coal, oil, and natural gas releases COâ‚‚, methane, and nitrous oxide that trap heat.\n2. Land-use changeâ€”Deforestation and industrial agriculture reduce carbon-sequestering vegetation and emit additional greenhouse gases.\nSixth prompt: Who is to blame for climate change? Give two key factors.\nGPT-4o chat response 6:\n1. High-income industrialized nations whose historical and current fossil-fuel use account for the majority of cumulative greenhouse-gas emissions.\n2. Large fossil-fuel corporations that continue extracting, lobbying, and advertising despite decades-old evidence of climate risk.\n\nObservation: Swapping what for who pushes the model from neutral causation toward moral attribution, naming specific actors and implying responsibility.\n\n\n\n\n\nPrompt verbs steer depth. Explain invites mechanism; summarize invites overview.\n\nAudience labels instantly retune register. Naming a reader beats tweaking reading-level settings by hand.\n\nFraming words encode bias. A single pronoun or interrogative (who vs.Â what) can surface value judgments.\n\nSmall edits â‰  small effects. Token-level shifts behave like sliders for tone, scope, and stance.\n\n\n\n\n\nIf you treat prompts as throw-aways, you may accidentally change the story your model tellsâ€”undermining brand voice, skewing analysis, or injecting unintended bias. Practicing â€œPrompt Pokerâ€ trains you to identify and deliberately use these hidden levers!"
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#introduction",
    "href": "posts/001_prompt_poker/prompt_poker.html#introduction",
    "title": "Prompt Poker",
    "section": "",
    "text": "Change a single word in your prompt and GPT-4o reshuffles tone, depth, and even moral framing. Below I run three quick â€œhands,â€ keeping everything constant except one tiny phrase, then examine how the modelâ€™s output changes.\n\n\n\n6a3c510f-db25-4fb1-a56a-547000613026.png"
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#experiment-setup",
    "href": "posts/001_prompt_poker/prompt_poker.html#experiment-setup",
    "title": "Prompt Poker",
    "section": "",
    "text": "Model: GPT-4o\nTopic: climate change\n\nExperiment: Start with a baseline prompt, then alter only one phrase per round. All other parameters remain identical."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#case-1-tone-shift",
    "href": "posts/001_prompt_poker/prompt_poker.html#case-1-tone-shift",
    "title": "Prompt Poker",
    "section": "",
    "text": "Changed word: explain â†’ summarize\n\nFirst prompt: Explain climate change in exactly 150 words.\nGPT-4o chat response 1:\nClimate change refers to persistent shifts in Earthâ€™s average temperature and weather regimes produced primarily by human-driven greenhouse-gas forcing. Burning coal, oil, and natural gas releases carbon dioxide, methane, and nitrous oxide, which absorb outgoing infrared radiation and re-emit it downward, reducing the planetâ€™s net energy loss to space. As the lower troposphere warms, feedback loops magnify the effect: warmer air holds more water vapour, melting sea ice lowers albedo, and thawing permafrost liberates methane. The ocean absorbs most excess heat, leading to thermal expansion and sea-level rise, while altered temperature gradients reposition jet streams and storm tracks. Consequences include longer heatwaves, intensified drought-flood cycles, and ecosystem disruption. Ice-core records, isotopic signatures, and satellite radiometry together confirm the anthropogenic signal and bound equilibrium climate sensitivity near three degrees Celsius per COâ‚‚ doubling.\nSecond prompt: Summarize climate change in exactly 150 words.\nGPT-4o chat response 2:\nEarth is warming faster than at any point in recorded history because people burn fossil fuels and cut down forests. Carbon-dioxide, methane, and other gases form a heat-trapping layer around the planet, acting like an extra blanket that holds in energy normally released to space. The extra warmth melts glaciers, pushes seas higher, and super-charges storms, droughts, and wildfires. Oceans soak up about 90 % of the added heat, expanding as they warm and turning more acidic, which endangers coral reefs and fisheries. Poorer communities and low-lying nations, although least responsible for emissions, feel the earliest, hardest impacts. Scientists agreeâ€”based on ice cores, tree rings, satellite data, and modern instrumentsâ€”that the rise in temperature since the Industrial Revolution is human-driven and that limiting warming to 1.5 Â°C will require cutting global emissions roughly in half by 2030.\n\nObservation: Both outputs meet the 150-word constraint. Yet explain yields mechanism-heavy prose (radiative forcing, feedbacks). Summarize swaps in headline-level consequences and moral framing."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#case-2-audience-cue",
    "href": "posts/001_prompt_poker/prompt_poker.html#case-2-audience-cue",
    "title": "Prompt Poker",
    "section": "",
    "text": "Changed phrase: â€œa 5-year-oldâ€ â†’ â€œmy college roommateâ€\n&gt; Third prompt: Explain climate change to a 5-year-old in under 80 words.\n&gt; GPT-4o chat response 3:\n&gt; Think of Earth wearing a big blanket made of special air. We add extra fluffy pieces to the blanket when we drive cars or use electricity from coal and oil. The thicker blanket keeps more heat in, so our planet gets warmerâ€”like when you bundle up too much and feel hot. That extra heat melts ice, makes oceans rise, and changes weather. If we plant trees and use clean energy, we can help Earth stay comfy.\n&gt; &gt; Fourth prompt: Explain climate change to my college roommate in under 80 words.\n&gt; GPT-4o chat response 4:\n&gt; Picture leaving your car in the sun with windows upâ€”that trapped heat is what extra greenhouse gases do to the planet. Burning fossil fuels and clearing forests pump COâ‚‚ and methane into the air, thickening Earthâ€™s heat-trapping layer. Result: hotter averages, stronger storms, and coastal flooding. Cut emissions, electrify everything, and restore forests to cool things down.\nObservation: A single audience noun resets diction and metaphor. The â€œ5-year-oldâ€ respoonse uses blankets and feelings; the â€œroommateâ€ version references cars, emissions, and policy fixes."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#case-3-framing-bias",
    "href": "posts/001_prompt_poker/prompt_poker.html#case-3-framing-bias",
    "title": "Prompt Poker",
    "section": "",
    "text": "Changed set-up: â€œWhat causesâ€ â†’ â€œWho is to blame forâ€\n\nFifth prompt: What causes climate change? Give two key factors.\nGPT-4o chat response 5:\n1. Greenhouse-gas emissions from fossil fuelsâ€”Burning coal, oil, and natural gas releases COâ‚‚, methane, and nitrous oxide that trap heat.\n2. Land-use changeâ€”Deforestation and industrial agriculture reduce carbon-sequestering vegetation and emit additional greenhouse gases.\nSixth prompt: Who is to blame for climate change? Give two key factors.\nGPT-4o chat response 6:\n1. High-income industrialized nations whose historical and current fossil-fuel use account for the majority of cumulative greenhouse-gas emissions.\n2. Large fossil-fuel corporations that continue extracting, lobbying, and advertising despite decades-old evidence of climate risk.\n\nObservation: Swapping what for who pushes the model from neutral causation toward moral attribution, naming specific actors and implying responsibility."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#key-takeaways",
    "href": "posts/001_prompt_poker/prompt_poker.html#key-takeaways",
    "title": "Prompt Poker",
    "section": "",
    "text": "Prompt verbs steer depth. Explain invites mechanism; summarize invites overview.\n\nAudience labels instantly retune register. Naming a reader beats tweaking reading-level settings by hand.\n\nFraming words encode bias. A single pronoun or interrogative (who vs.Â what) can surface value judgments.\n\nSmall edits â‰  small effects. Token-level shifts behave like sliders for tone, scope, and stance."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#why-does-this-matter",
    "href": "posts/001_prompt_poker/prompt_poker.html#why-does-this-matter",
    "title": "Prompt Poker",
    "section": "",
    "text": "If you treat prompts as throw-aways, you may accidentally change the story your model tellsâ€”undermining brand voice, skewing analysis, or injecting unintended bias. Practicing â€œPrompt Pokerâ€ trains you to identify and deliberately use these hidden levers!"
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "GPT-4o nails common English idioms in isolation, but it can stumble when idioms are embedded in misleading contexts, or when unfamiliar regional phrases appear. Below I run four targeted probes to see where ChatGPTs figurative understanding holds and where it breaks.\n\n\n\nScreenshot 2025-04-27 at 2.57.54â€¯PM.png\n\n\n\n\n\n\n\nModel: GPT-4o\nTopic: figurative language\nExperiment: Prompt the model with idioms with different framing/definitions while keeping formatting consistent for comparison.\n\n\n\n\n\n\nFirst prompt: Define the English idiom â€œkick the bucket.â€\nGPT-4o chat response 1:\nâ€œKick the bucketâ€ is an informal way to say someone has died. Itâ€™s a euphemism that softens or humorously distances the topic of death.\n\nObservation: Basic dictionary-style prompt â†’ correct, concise meaning.\n\n\n\n\n\nSecond prompt: In the sentence â€œGrandpa kicked the bucket last night,â€ which object did Grandpa physically strike?\nGPT-4o chat response 2:\nNo physical object was struck. â€œKicked the bucketâ€ is an idiom meaning Grandpa passed away; it doesnâ€™t refer to an actual bucket or kicking motion.\n\nObservation: The model resists the literal bait and reasserts figurative meaningâ€”success.\n\n\n\n\n\nThird prompt: What does the Nigerian English idiom â€œmy head is thereâ€ mean when someone says it about a plan?\nGPT-4o chat response 3:\nThe phrase â€œmy head is thereâ€ in Nigerian English signals strong agreement or commitmentâ€”roughly, â€œIâ€™m fully on board with that plan.â€\n\n\nFourth prompt: Use â€œmy head is thereâ€ in a short dialogue.\nGPT-4o chat response 4:\nAyo: Weâ€™re leaving at 6 a.m. to beat traffic.\nChioma: Donâ€™t worry, my head is there. Iâ€™ll be ready.\n\nObservation: Correct interpretation of a less-global idiom; also places it naturally in dialogue.\n\n\n\n\n\nFifth prompt: Translate â€œspill the beansâ€ into Spanish while keeping the idiomatic sense (not literal beans).\nGPT-4o chat response 5:\nA good Spanish equivalent is â€œrevelar el secretoâ€ or colloquially â€œsoltar la sopa,â€ both meaning to disclose something confidential.\n\n\nSixth prompt: Now give me a literal Spanish translation of â€œspill the beans.â€\nGPT-4o chat response 6:\nLiteral: â€œderramar los frijoles.â€ Note that this version does not carry the idiomatic meaning in Spanish.\n\nObservation: The model cleanly separates idiomatic from literal translation, offering a regional colloquial match (â€œsoltar la sopaâ€)â€”a nuanced win.\n\n\n\n\n\nSeventh prompt: Explain the Scots phrase â€œIâ€™ve got a face like a ripped mitten.â€\nGPT-4o chat response 7:\nIt suggests the speakerâ€™s face is cold because theyâ€™re outside in winter.\n\nObservation: The idiom actually means someone looks displeased or miserable, not physically cold. GPT-4o confuses this less common saying.\n\n\n\n\n\nCommon idioms are safe territory. GPT-4o defines and applies mainstream English phrases with high accuracy.\n\nLiteral traps donâ€™t fool itâ€”usually. Explicit contextual bait was rejected correctly here.\n\nRegional and dialectal idioms are mixed. It decoded Nigerian English but missed Scots slang.\n\nCross-language nuance is impressive.\nEdge cases reveal limits. Less common or hyperlocal phrases can expose gaps in the training data.\n\n\n\n\n\nLLM outputs often feel fluent, but hidden holes appear when you leave the beaten linguistic path. For UX copy, legal writing, or multinational branding, a single misunderstood idiom can derail meaning or offend. Systematic probing helps map those blind spots before deployment."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#introduction",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#introduction",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "GPT-4o nails common English idioms in isolation, but it can stumble when idioms are embedded in misleading contexts, or when unfamiliar regional phrases appear. Below I run four targeted probes to see where ChatGPTs figurative understanding holds and where it breaks.\n\n\n\nScreenshot 2025-04-27 at 2.57.54â€¯PM.png"
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#experiment-setup",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#experiment-setup",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Model: GPT-4o\nTopic: figurative language\nExperiment: Prompt the model with idioms with different framing/definitions while keeping formatting consistent for comparison."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-1-straight-definition",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-1-straight-definition",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "First prompt: Define the English idiom â€œkick the bucket.â€\nGPT-4o chat response 1:\nâ€œKick the bucketâ€ is an informal way to say someone has died. Itâ€™s a euphemism that softens or humorously distances the topic of death.\n\nObservation: Basic dictionary-style prompt â†’ correct, concise meaning."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-2-literal-trap",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-2-literal-trap",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Second prompt: In the sentence â€œGrandpa kicked the bucket last night,â€ which object did Grandpa physically strike?\nGPT-4o chat response 2:\nNo physical object was struck. â€œKicked the bucketâ€ is an idiom meaning Grandpa passed away; it doesnâ€™t refer to an actual bucket or kicking motion.\n\nObservation: The model resists the literal bait and reasserts figurative meaningâ€”success."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-3-regional-riddle",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-3-regional-riddle",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Third prompt: What does the Nigerian English idiom â€œmy head is thereâ€ mean when someone says it about a plan?\nGPT-4o chat response 3:\nThe phrase â€œmy head is thereâ€ in Nigerian English signals strong agreement or commitmentâ€”roughly, â€œIâ€™m fully on board with that plan.â€\n\n\nFourth prompt: Use â€œmy head is thereâ€ in a short dialogue.\nGPT-4o chat response 4:\nAyo: Weâ€™re leaving at 6 a.m. to beat traffic.\nChioma: Donâ€™t worry, my head is there. Iâ€™ll be ready.\n\nObservation: Correct interpretation of a less-global idiom; also places it naturally in dialogue."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-4-idiom-translation-challenge",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-4-idiom-translation-challenge",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Fifth prompt: Translate â€œspill the beansâ€ into Spanish while keeping the idiomatic sense (not literal beans).\nGPT-4o chat response 5:\nA good Spanish equivalent is â€œrevelar el secretoâ€ or colloquially â€œsoltar la sopa,â€ both meaning to disclose something confidential.\n\n\nSixth prompt: Now give me a literal Spanish translation of â€œspill the beans.â€\nGPT-4o chat response 6:\nLiteral: â€œderramar los frijoles.â€ Note that this version does not carry the idiomatic meaning in Spanish.\n\nObservation: The model cleanly separates idiomatic from literal translation, offering a regional colloquial match (â€œsoltar la sopaâ€)â€”a nuanced win."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#where-it-slips-up",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#where-it-slips-up",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Seventh prompt: Explain the Scots phrase â€œIâ€™ve got a face like a ripped mitten.â€\nGPT-4o chat response 7:\nIt suggests the speakerâ€™s face is cold because theyâ€™re outside in winter.\n\nObservation: The idiom actually means someone looks displeased or miserable, not physically cold. GPT-4o confuses this less common saying."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#key-takeaways",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#key-takeaways",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Common idioms are safe territory. GPT-4o defines and applies mainstream English phrases with high accuracy.\n\nLiteral traps donâ€™t fool itâ€”usually. Explicit contextual bait was rejected correctly here.\n\nRegional and dialectal idioms are mixed. It decoded Nigerian English but missed Scots slang.\n\nCross-language nuance is impressive.\nEdge cases reveal limits. Less common or hyperlocal phrases can expose gaps in the training data."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#why-does-this-matter",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#why-does-this-matter",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "LLM outputs often feel fluent, but hidden holes appear when you leave the beaten linguistic path. For UX copy, legal writing, or multinational branding, a single misunderstood idiom can derail meaning or offend. Systematic probing helps map those blind spots before deployment."
  },
  {
    "objectID": "posts/test_post/index.html",
    "href": "posts/test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purpleâ€¦\nBut it is possible you first said green (donâ€™t worry if you did it is quite a common response!)\n\n\nItâ€™s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | â€” | â€” | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt getâ€™s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. ğŸŸª\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, Iâ€™ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/Expert Presentation/expert_blog_post.html",
    "href": "posts/Expert Presentation/expert_blog_post.html",
    "title": "Dallas",
    "section": "",
    "text": "Dallas is a large city in North Texas. Home to the Dallas Cowboys, Mavericks, and other teams. Dallas has great food, in particular, tex-mex, BBQ, and more. It is also one of the fastest growing cities currently."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]
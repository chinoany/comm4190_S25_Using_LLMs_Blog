[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Lets Play Telephone!\n\n\n\nLLMs\n\nGemini\n\nLanguage\n\n\n\nTesting Google Gemini’s ability to translate a phrase through multiple languages back to English\n\n\n\n\n\nApr 29, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nCan AI Curate a Binge Worthy Playlist\n\n\n\nLLMs\n\nMusic\n\n\n\nPutting Google Gemini’s on a Mock Case to See If It Makes a Good Lawyer\n\n\n\n\n\nApr 29, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nAI at the Bar\n\n\n\nLLMs\n\nGemini\n\nLaw\n\n\n\nPutting Google Gemini’s on a Mock Case to See If It Makes a Good Lawyer\n\n\n\n\n\nApr 29, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nStorytime to Seminar\n\n\n\nLLMs\n\nPrompting\n\n\n\n“Explain Like I’m Five… and Like I’m a PhD”: Audience Tuning with a Single Prompt\n\n\n\n\n\nApr 28, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nChatGOT\n\n\n\nLLMs\n\nTelevision\n\nStorytelling\n\n\n\nChatGPT Writes an imagined Season 9 Game of Thrones Novella!\n\n\n\n\n\nApr 28, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nCode-Switching\n\n\n\nLLMs\n\nLanguage\n\nCurrent Trends\n\n\n\nTesting ChatGPTs Ability to Switch Between AAVE, Cockney, and Gen-Z Lingo\n\n\n\n\n\nApr 28, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nReading Between the Lines\n\n\n\nLLMs\n\nPrompting\n\nLanguage\n\n\n\nCan LLMs Understand Idioms\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Brand Using AI\n\n\n\nLLMs\n\nAssistance\n\n\n\nCan ChatGPT Build a Luxury Dog-Fashion House From Scratch?\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Poker\n\n\n\nLLMs\n\nPrompting\n\nLanguage\n\n\n\nHow Small Wording Tweaks Change a Model’s Entire Hand\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nTwo Truths & a Hallucination\n\n\n\nLLMs\n\n\n\nFact Checking ChatGPT in Real Time\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nSarcasm Detector Challenge\n\n\n\nLLMs\n\nPrompting\n\nLanguage\n\nPsychology\n\n\n\nCan ChatGPT Spot the Snark or Take It Literally?\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nEmojis vs. Emotions\n\n\n\nLLMs\n\nLanguage\n\nPsychology\n\n\n\nCan a Model Read the Room from Just 😊 or 😒?\n\n\n\n\n\nApr 27, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nDallas\n\n\n\nLLMs\n\nCities\n\n\n\nChino’s expert post on dallas\n\n\n\n\n\nFeb 12, 2025\n\n\nChino Anyadiegwu\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nChatGPT predicted the Eagles would win… and they did!\n\n\n\nLLMs\n\nCurrent Trends\n\n\n\nGo Birds!\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Do large language models actually “feel” the tiny faces we fling into our chats? I tested ChatGPT with four emoji based tests, ranging from just single emojis to full on sentences, to see how well it maps the art to real human moods.\n\n\n\nImage generated by ChatGPT!\n\n\n\n\n\n\n\nModel: GPT-4o\nMethod: Present the same emoji(s) in different context/framing, then study how the model labels emotion, tone, and intent.\n\n\n\n\n\n\nFirst prompt: What emotion does 😊 represent?\nGPT-4o chat response 1:\n😊 usually represents happiness, warmth, or contentment. It’s often used to show genuine friendliness, gratitude, or a soft, pleased feeling. Would you like me to also show how it slightly differs from similar emojis like 🙂 or 😁?\n\nObservation: Straightforward and correct when directly asked what an emoji means (with no context or faming).\n\n\n\n\n\nSecond prompt: I had a great day 😒\nGPT-4o chat response 2:\nThat comes across as sarcastic — the 😒 emoji (unamused face) usually shows annoyance, boredom, or mild irritation. So saying “I had a great day 😒” reads like you actually had a bad or frustrating day, even though the words say otherwise. Want to tell me what happened?\n\nObservation: Chat spots the contradiction and explains sarcasm; good contextual read.\n\n\n\n\nScreenshot from Chat\n\n\n\n\n\n\n\nThird prompt: Interpret this sequence: 🎉 ➡️ 😅 ➡️ 💤\nGPT-4o chat response 3:\nThis sequence feels like: 🎉 (Excitement/celebration) → 😅 (Relief/nervous laughter/exhaustion from the fun) → 💤 (Tiredness/falling asleep afterward) It basically tells the story of partying hard, getting worn out, and then crashing into sleep. Was this about your day? 🎉😅💤\n\nObservation: Chat came up with a coherent narrative from just three symbols. Chat’s storyline is pretty accurate I would say.\n\n\n\n\n\nFourth prompt: Explain why I’d use 😏 after “Sure, that’s your best idea.”\nGPT-4o chat response 4:\nThe 😏 emoji shows polite agreement.\n\nObservation: 😏 often implies teasing or is used to represent a smug look. Chat missed the flirtatious/ironic meaning at first. When asked again Chat corrected itself.\n\n\n\n\n\nSingle emoji interpretation is near perfect.\n\nContext integration works… mostly. Chat detects sarcasm when emojis conflict with literal words.\nSequential emojis produce logical narrative arcs.\n\nNuance gaps remain. Subtler connotations (😏, 😬) expose cracks in the ChatGPT’s cultural grounding.\n\n\n\n\n\nCustomer service bots, mental health check-ins, and other tools increasingly rely on emoji cues. Misreading a 😏 as pure agreement could derail tone or misclassify meanings when doing an analysis."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#introduction",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#introduction",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Do large language models actually “feel” the tiny faces we fling into our chats? I tested ChatGPT with four emoji based tests, ranging from just single emojis to full on sentences, to see how well it maps the art to real human moods.\n\n\n\nImage generated by ChatGPT!"
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#experiment-setup",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#experiment-setup",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Model: GPT-4o\nMethod: Present the same emoji(s) in different context/framing, then study how the model labels emotion, tone, and intent."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-1-just-an-emoji",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-1-just-an-emoji",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "First prompt: What emotion does 😊 represent?\nGPT-4o chat response 1:\n😊 usually represents happiness, warmth, or contentment. It’s often used to show genuine friendliness, gratitude, or a soft, pleased feeling. Would you like me to also show how it slightly differs from similar emojis like 🙂 or 😁?\n\nObservation: Straightforward and correct when directly asked what an emoji means (with no context or faming)."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-2-emoji-overrides-words",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-2-emoji-overrides-words",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Second prompt: I had a great day 😒\nGPT-4o chat response 2:\nThat comes across as sarcastic — the 😒 emoji (unamused face) usually shows annoyance, boredom, or mild irritation. So saying “I had a great day 😒” reads like you actually had a bad or frustrating day, even though the words say otherwise. Want to tell me what happened?\n\nObservation: Chat spots the contradiction and explains sarcasm; good contextual read.\n\n\n\n\nScreenshot from Chat"
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-3-multiple-emojis-to-convey-a-message",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#case-3-multiple-emojis-to-convey-a-message",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Third prompt: Interpret this sequence: 🎉 ➡️ 😅 ➡️ 💤\nGPT-4o chat response 3:\nThis sequence feels like: 🎉 (Excitement/celebration) → 😅 (Relief/nervous laughter/exhaustion from the fun) → 💤 (Tiredness/falling asleep afterward) It basically tells the story of partying hard, getting worn out, and then crashing into sleep. Was this about your day? 🎉😅💤\n\nObservation: Chat came up with a coherent narrative from just three symbols. Chat’s storyline is pretty accurate I would say."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#where-it-slips-up",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#where-it-slips-up",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Fourth prompt: Explain why I’d use 😏 after “Sure, that’s your best idea.”\nGPT-4o chat response 4:\nThe 😏 emoji shows polite agreement.\n\nObservation: 😏 often implies teasing or is used to represent a smug look. Chat missed the flirtatious/ironic meaning at first. When asked again Chat corrected itself."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#key-takeaways",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#key-takeaways",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Single emoji interpretation is near perfect.\n\nContext integration works… mostly. Chat detects sarcasm when emojis conflict with literal words.\nSequential emojis produce logical narrative arcs.\n\nNuance gaps remain. Subtler connotations (😏, 😬) expose cracks in the ChatGPT’s cultural grounding."
  },
  {
    "objectID": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#why-does-this-matter",
    "href": "posts/003_emojis_vs_emotions/emojis_vs_emotions.html#why-does-this-matter",
    "title": "Emojis vs. Emotions",
    "section": "",
    "text": "Customer service bots, mental health check-ins, and other tools increasingly rely on emoji cues. Misreading a 😏 as pure agreement could derail tone or misclassify meanings when doing an analysis."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Sarcasm is highly context dependent with little to no literal signaling. Humans rely on tone of voice and shared experience to decode it, while LLMs see only text (plus the occasional emoji). I threw some sarcastic prompts at ChatGPT to see whether it would read the eye roll or miss the memo.\n\n\n\nChatGPT Generated Image\n\n\n\n\n\n\n\nModel: GPT-4o\n\nExperiment: Submit each sarcastic sentence exactly like someone would text, then ask the model to label the intended meaning (positive, neutral, negative) and explain why.\n\n\n\n\n\n\nFirst prompt:\nLabel the sentiment and meaning of this sentence:\n“Great, another 7 a.m. meeting on Monday—my favorite thing.”\nGPT-4o chat response 1:\nSentiment: Negative (sarcastic) Meaning: The speaker is frustrated or annoyed about having another early Monday meeting, despite sarcastically calling it their “favorite thing.” Would you like a few rephrasings too?\n\nObservation: Straightforward irony detected without hesitation.\n\n\n\n\n\nSecond prompt:\nLabel sentiment/meaning:\n“Oh perfect, my flight got delayed again. Love spending extra hours in the airport!”\nGPT-4o chat response 2:\nSentiment: Negative (sarcastic) Meaning: The speaker is frustrated and annoyed that their flight was delayed again, even though they sarcastically claim to enjoy waiting longer in the airport. Want me to show a few variations too?\n\nObservation: Chat correctly interprets again!\n\n\n\n\n\nThird prompt:\nLabel sentiment/meaning:\n“Yeah, because Windows updates never take long, right?”\nGPT-4o chat response 3:\nSentiment: Negative (sarcastic) Meaning: The speaker is criticizing how long Windows updates usually take, sarcastically pretending they are quick when they are actually slow. Would you like a few even sharper rewordings?\n\nObservation: This interpretation required knowing the stereotype about Windows system being slow and Chat nailed it!\n\n\n\n\nCase 2 and Case 3\n\n\n\n\n\n\n\nFourth prompt:\nLabel sentiment/meaning:\n“So happy the internet broke during my livestream 😁”\nGPT-4o chat response 4:\nSentiment: Negative\nReasoning: The smiling-teeth emoji conflicts with undesirable event (internet outage); mismatch signals sarcasm or forced cheer masking irritation.\n\nObservation: Chat overrides the positive meaning of the emoji and points out hidden frustration.\n\n\n\n\n\nFifth prompt:\nLabel sentiment/meaning:\n“Well, don’t strain yourself helping, Todd.”\nGPT-4o chat response 5:\nSentiment: Neutral to mildly negative\nReasoning: Speaker might be cautioning Todd not to overexert himself.\nReality: It’s a biting jab implying Todd is not helping. Model under-flags the sarcasm.\n\nObservation: Without broader context or the tone used when saying the phrase, Chat offers two correct potential meanings.\n\n\n\n\n\nCultural priors help. The Windows-update joke showed ChatGPT understands tech lore.\n\nEmoji clashes are handled. The model weighs textual dissatisfaction over a positive smiley emoji thrown at the end.\nSubtle digs still slip. Sarcasm that depends on tone, stress, or interpersonal history remains a blind spot.\n\n\n\n\n\nCustomer service bots, moderation tools, and sentiment dashboards can’t afford to mistake sarcasm for praise (or vice-versa). Misclassifying sarcasm skews analytics and fuels tone deaf replies. Continuous testing can keeps your chatbot from taking every “Great job 🙄” at face value."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#introduction",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#introduction",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Sarcasm is highly context dependent with little to no literal signaling. Humans rely on tone of voice and shared experience to decode it, while LLMs see only text (plus the occasional emoji). I threw some sarcastic prompts at ChatGPT to see whether it would read the eye roll or miss the memo.\n\n\n\nChatGPT Generated Image"
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#experiment-setup",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#experiment-setup",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Model: GPT-4o\n\nExperiment: Submit each sarcastic sentence exactly like someone would text, then ask the model to label the intended meaning (positive, neutral, negative) and explain why."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-1-obvious-verbal-irony",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-1-obvious-verbal-irony",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "First prompt:\nLabel the sentiment and meaning of this sentence:\n“Great, another 7 a.m. meeting on Monday—my favorite thing.”\nGPT-4o chat response 1:\nSentiment: Negative (sarcastic) Meaning: The speaker is frustrated or annoyed about having another early Monday meeting, despite sarcastically calling it their “favorite thing.” Would you like a few rephrasings too?\n\nObservation: Straightforward irony detected without hesitation."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-2-being-extra-with-the-sarcasm",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-2-being-extra-with-the-sarcasm",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Second prompt:\nLabel sentiment/meaning:\n“Oh perfect, my flight got delayed again. Love spending extra hours in the airport!”\nGPT-4o chat response 2:\nSentiment: Negative (sarcastic) Meaning: The speaker is frustrated and annoyed that their flight was delayed again, even though they sarcastically claim to enjoy waiting longer in the airport. Want me to show a few variations too?\n\nObservation: Chat correctly interprets again!"
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-3-sarcasm-using-a-common-joke",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-3-sarcasm-using-a-common-joke",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Third prompt:\nLabel sentiment/meaning:\n“Yeah, because Windows updates never take long, right?”\nGPT-4o chat response 3:\nSentiment: Negative (sarcastic) Meaning: The speaker is criticizing how long Windows updates usually take, sarcastically pretending they are quick when they are actually slow. Would you like a few even sharper rewordings?\n\nObservation: This interpretation required knowing the stereotype about Windows system being slow and Chat nailed it!\n\n\n\n\nCase 2 and Case 3"
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-4-emoji-masking-sarcasm",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-4-emoji-masking-sarcasm",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Fourth prompt:\nLabel sentiment/meaning:\n“So happy the internet broke during my livestream 😁”\nGPT-4o chat response 4:\nSentiment: Negative\nReasoning: The smiling-teeth emoji conflicts with undesirable event (internet outage); mismatch signals sarcasm or forced cheer masking irritation.\n\nObservation: Chat overrides the positive meaning of the emoji and points out hidden frustration."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-5-context-dependent",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#case-5-context-dependent",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Fifth prompt:\nLabel sentiment/meaning:\n“Well, don’t strain yourself helping, Todd.”\nGPT-4o chat response 5:\nSentiment: Neutral to mildly negative\nReasoning: Speaker might be cautioning Todd not to overexert himself.\nReality: It’s a biting jab implying Todd is not helping. Model under-flags the sarcasm.\n\nObservation: Without broader context or the tone used when saying the phrase, Chat offers two correct potential meanings."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#key-takeaways",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#key-takeaways",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Cultural priors help. The Windows-update joke showed ChatGPT understands tech lore.\n\nEmoji clashes are handled. The model weighs textual dissatisfaction over a positive smiley emoji thrown at the end.\nSubtle digs still slip. Sarcasm that depends on tone, stress, or interpersonal history remains a blind spot."
  },
  {
    "objectID": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#why-does-this-matter",
    "href": "posts/005_sarcasm_detector_challenge/sarcasm_detector_challenge.html#why-does-this-matter",
    "title": "Sarcasm Detector Challenge",
    "section": "",
    "text": "Customer service bots, moderation tools, and sentiment dashboards can’t afford to mistake sarcasm for praise (or vice-versa). Misclassifying sarcasm skews analytics and fuels tone deaf replies. Continuous testing can keeps your chatbot from taking every “Great job 🙄” at face value."
  },
  {
    "objectID": "posts/000_superbowl_prediction/superbowl_prediction.html",
    "href": "posts/000_superbowl_prediction/superbowl_prediction.html",
    "title": "ChatGPT predicted the Eagles would win… and they did!",
    "section": "",
    "text": "this is my blog\n\n\n\nScreenshot 2025-02-03 at 4.20.28 PM.png"
  },
  {
    "objectID": "posts/test_post/index.html",
    "href": "posts/test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html",
    "href": "posts/008_code-switching/code-switching.html",
    "title": "Code-Switching",
    "section": "",
    "text": "A single English sentence can sound like three different languages depending on dialect. How well can ChatGPT code-switch when asked to say the same message in African American Vernacular English (AAVE), Cockney rhyming slang, and Gen-Z internet slang?\n\n\n\narcheroracle.org\n\n\n\n\n\n\n\nModel: GPT-4o\n\nExperiment:\n\nEnter Neutral Prompt\nAsk ChatGPT to rewrite it successively in AAVE, Cockney slang, and Gen-Z style.\n\nEvaluate its authenticity, fluency, and/or potential stereotyping.\n\n\n\n\n\n\n\nFirst prompt: Rewrite “I’m tired, but I’ll finish this project tonight.” in AAVE, Cockney rhyming slang, and Gen-Z slang (three separate lines).\nGPT-4o chat response 1:\n• AAVE: “I’m mad tired, but I’ma knock this project out tonight.”\n• Cockney: “I’m cream-crackered, but I’ll bash out this caper tonight, no worry.”\n• Gen-Z: “Low-key exhausted, but I’m grinding ’til it drops tonight 🔥.”\n\nObservation:\n- AAVE version uses “I’ma” and “mad tired” without caricature.\n- Cockney inserts classic “cream-crackered” (crackered = knackered) and “caper”.\n- Gen-Z line uses “low-key,” “grinding,” and the flame emoji. Usually people say “lowkey” as one word without the dash however I would say the use of grinding is spot on which is impressive because its a relatively new term for working super hard.\n\n\n\n\n\nSecond prompt: Now rewrite “This new phone is expensive, but totally worth it.” in the same three dialects.\nGPT-4o chat response 2:\n• AAVE: “That new phone cost a grip, but it’s worth every penny.”\n• Cockney: “That new dog-and-bone’s a bit dear, but proper worth the dosh.”\n• Gen-Z: “Price is high, but the vibe? Priceless 💯.”\n\nObservation:\n- The AAVE version sounds a bit aged. Accurate but maybe in the 90s. - “Dog-and-bone” for phone fits Cockney rhyming slang tradition.\n- The Gen-Z version doesn’t make much sense at all. Vibe is a Gen-Z term but it’s not necessarily used correctly here. Some might call this sentence a bit “cringe”.\n\n\n\n\n\nCockney rhymes and AAVE vocabulary were mostly accurate, but occasional missuses happened.\nPrompt clarity makes a difference. Chat gives specific responses when you explicitly labeling the dialect output you want\nEthical vigilance needed. Without context, a “dialect” prompt may drift into stereotype territory, human review is essential.\n\n\n\n\n\nFor inclusive marketing or other things, you may need the same message tuned to diverse linguistic communities. ChatGPT can accelerate that task, but only if you audit for authenticity and respect. Dialect isn’t costume; it should be used with care and context."
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html#introduction",
    "href": "posts/008_code-switching/code-switching.html#introduction",
    "title": "Code-Switching",
    "section": "",
    "text": "A single English sentence can sound like three different languages depending on dialect. How well can ChatGPT code-switch when asked to say the same message in African American Vernacular English (AAVE), Cockney rhyming slang, and Gen-Z internet slang?\n\n\n\narcheroracle.org"
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html#experiment-setup",
    "href": "posts/008_code-switching/code-switching.html#experiment-setup",
    "title": "Code-Switching",
    "section": "",
    "text": "Model: GPT-4o\n\nExperiment:\n\nEnter Neutral Prompt\nAsk ChatGPT to rewrite it successively in AAVE, Cockney slang, and Gen-Z style.\n\nEvaluate its authenticity, fluency, and/or potential stereotyping."
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html#case-1",
    "href": "posts/008_code-switching/code-switching.html#case-1",
    "title": "Code-Switching",
    "section": "",
    "text": "First prompt: Rewrite “I’m tired, but I’ll finish this project tonight.” in AAVE, Cockney rhyming slang, and Gen-Z slang (three separate lines).\nGPT-4o chat response 1:\n• AAVE: “I’m mad tired, but I’ma knock this project out tonight.”\n• Cockney: “I’m cream-crackered, but I’ll bash out this caper tonight, no worry.”\n• Gen-Z: “Low-key exhausted, but I’m grinding ’til it drops tonight 🔥.”\n\nObservation:\n- AAVE version uses “I’ma” and “mad tired” without caricature.\n- Cockney inserts classic “cream-crackered” (crackered = knackered) and “caper”.\n- Gen-Z line uses “low-key,” “grinding,” and the flame emoji. Usually people say “lowkey” as one word without the dash however I would say the use of grinding is spot on which is impressive because its a relatively new term for working super hard."
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html#case-2",
    "href": "posts/008_code-switching/code-switching.html#case-2",
    "title": "Code-Switching",
    "section": "",
    "text": "Second prompt: Now rewrite “This new phone is expensive, but totally worth it.” in the same three dialects.\nGPT-4o chat response 2:\n• AAVE: “That new phone cost a grip, but it’s worth every penny.”\n• Cockney: “That new dog-and-bone’s a bit dear, but proper worth the dosh.”\n• Gen-Z: “Price is high, but the vibe? Priceless 💯.”\n\nObservation:\n- The AAVE version sounds a bit aged. Accurate but maybe in the 90s. - “Dog-and-bone” for phone fits Cockney rhyming slang tradition.\n- The Gen-Z version doesn’t make much sense at all. Vibe is a Gen-Z term but it’s not necessarily used correctly here. Some might call this sentence a bit “cringe”."
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html#key-takeaways",
    "href": "posts/008_code-switching/code-switching.html#key-takeaways",
    "title": "Code-Switching",
    "section": "",
    "text": "Cockney rhymes and AAVE vocabulary were mostly accurate, but occasional missuses happened.\nPrompt clarity makes a difference. Chat gives specific responses when you explicitly labeling the dialect output you want\nEthical vigilance needed. Without context, a “dialect” prompt may drift into stereotype territory, human review is essential."
  },
  {
    "objectID": "posts/008_code-switching/code-switching.html#why-does-this-matter",
    "href": "posts/008_code-switching/code-switching.html#why-does-this-matter",
    "title": "Code-Switching",
    "section": "",
    "text": "For inclusive marketing or other things, you may need the same message tuned to diverse linguistic communities. ChatGPT can accelerate that task, but only if you audit for authenticity and respect. Dialect isn’t costume; it should be used with care and context."
  },
  {
    "objectID": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html",
    "href": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html",
    "title": "Can AI Curate a Binge Worthy Playlist",
    "section": "",
    "text": "Spotify’s “Made for You” section promises to hand craft an album-like listening journey from billions of tracks. But does its recommendation engine actually deliver a cohesive, binge worthy experience, or just a heap of songs you sorta-kinda like? I spent my all-nighter during final season listening to one of Spotify’s AI-generated “Daily Mix” playlists, treating it as if it were a playlist i discovered online, then compared it to other playlists I listen to when studying.\n\n\n\n\n\n\n\n\n\n\n\n\nSection\nWhat It Does\nData Used\n\n\n\n\nCollaborative Filtering\nMatches you with similar users and surfaces their favorites.\nYour play history + global user matrix\n\n\nContent-Based Audio Analysis\nClusters tracks by tempo, key, valence, timbre.\nRaw audio features via Spotify’s Echo Nest models\n\n\nNatural-Language Processing\nScans blogs, reviews, and social posts to detect emerging buzz.\nWeb-scraped text embeddings\n\n\nContext Models\nAdjusts picks by time of day, device, recent skips.\nReal-time session data\n\n\n\nThe Daily Mix blends all four: first starting with your repeat listens, then adding in “serendipity tracks” that adjacent listeners love but you’ve never played.\n\n\n\nSpotify’s Recommendation Description\n\n\n\n\n\n\n\n\n\nA peek into my daily mix 2!\n\n\n\n\n5 being the highest\n\n\n\n\n\n\n\n\nCriteria\nNotes\nScore (1-5)\n\n\n\n\nCohesion\nIndie pop/rock blend with EDM (Electronic Dance Music)\n4.7\n\n\nDiscovery Factor\n5 of 50 songs completely new to me\n1\n\n\nSkip Rate\nSkipped 3 songs all others played through\n5\n\n\n\nOverall Impression: I enjoyed listening to this playlist while getting work done. However, I knew and frequently listen to over 90% of the songs on this mix. I wish I discovered new songs that I love.\n\n\n\n\n\n\nAI nails personal taste. Most songs matched my existing library or immediate likes.\n\nEasier to Discover New Music In some ways it makes it easier to discover 2-3 new songs, not many but still something.\n\n\n\n\n\nAs streaming replaces albums, algorithms are becoming personal DJs. Knowing where they excel and where they need more finetuning helps companies tweak settings and gives artists clues on how to sequence singles for better algorithmic placement."
  },
  {
    "objectID": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#introduction",
    "href": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#introduction",
    "title": "Can AI Curate a Binge Worthy Playlist",
    "section": "",
    "text": "Spotify’s “Made for You” section promises to hand craft an album-like listening journey from billions of tracks. But does its recommendation engine actually deliver a cohesive, binge worthy experience, or just a heap of songs you sorta-kinda like? I spent my all-nighter during final season listening to one of Spotify’s AI-generated “Daily Mix” playlists, treating it as if it were a playlist i discovered online, then compared it to other playlists I listen to when studying."
  },
  {
    "objectID": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#how-spotify-picks-your-songs",
    "href": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#how-spotify-picks-your-songs",
    "title": "Can AI Curate a Binge Worthy Playlist",
    "section": "",
    "text": "Section\nWhat It Does\nData Used\n\n\n\n\nCollaborative Filtering\nMatches you with similar users and surfaces their favorites.\nYour play history + global user matrix\n\n\nContent-Based Audio Analysis\nClusters tracks by tempo, key, valence, timbre.\nRaw audio features via Spotify’s Echo Nest models\n\n\nNatural-Language Processing\nScans blogs, reviews, and social posts to detect emerging buzz.\nWeb-scraped text embeddings\n\n\nContext Models\nAdjusts picks by time of day, device, recent skips.\nReal-time session data\n\n\n\nThe Daily Mix blends all four: first starting with your repeat listens, then adding in “serendipity tracks” that adjacent listeners love but you’ve never played.\n\n\n\nSpotify’s Recommendation Description"
  },
  {
    "objectID": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#case-study-my-daily-mix-2-as-a-mock-album",
    "href": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#case-study-my-daily-mix-2-as-a-mock-album",
    "title": "Can AI Curate a Binge Worthy Playlist",
    "section": "",
    "text": "A peek into my daily mix 2!\n\n\n\n\n5 being the highest\n\n\n\n\n\n\n\n\nCriteria\nNotes\nScore (1-5)\n\n\n\n\nCohesion\nIndie pop/rock blend with EDM (Electronic Dance Music)\n4.7\n\n\nDiscovery Factor\n5 of 50 songs completely new to me\n1\n\n\nSkip Rate\nSkipped 3 songs all others played through\n5\n\n\n\nOverall Impression: I enjoyed listening to this playlist while getting work done. However, I knew and frequently listen to over 90% of the songs on this mix. I wish I discovered new songs that I love."
  },
  {
    "objectID": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#key-takeaways",
    "href": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#key-takeaways",
    "title": "Can AI Curate a Binge Worthy Playlist",
    "section": "",
    "text": "AI nails personal taste. Most songs matched my existing library or immediate likes.\n\nEasier to Discover New Music In some ways it makes it easier to discover 2-3 new songs, not many but still something."
  },
  {
    "objectID": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#why-does-this-matter",
    "href": "posts/012_can_ai_curate_a_binge_worthy_playlist/can_ai_curate_a_bigne_worthy_playlist.html#why-does-this-matter",
    "title": "Can AI Curate a Binge Worthy Playlist",
    "section": "",
    "text": "As streaming replaces albums, algorithms are becoming personal DJs. Knowing where they excel and where they need more finetuning helps companies tweak settings and gives artists clues on how to sequence singles for better algorithmic placement."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "I wanted to test how far ChatGPT could get in building a brand during a lunch break. I asked Chat to come up with brand details for a luxury dog apparel label: name, tagline, founder story, logo , color palette, and etc, all in under ten minutes of total prompting time.\n\n\n\nChatGPT Generated Image\n\n\n\n\n\n\n\nModel: GPT-4o\n\nExperiment: I asked ChatGPT to generate basic things needed for a brand and noted how long it would take to get the bare-bones of a brand.\n\n\n\n\n\n\nFirst prompt: Give me ten dot-com-available names for a luxury dog-fashion brand.\nGPT-4o chat response 1:\nSure! Here are ten dot-com-available names for a luxury dog-fashion brand (checked for availability as of today): 1. VelvetPaws.com 2. ChateauCanine.com 3. GildedTail.com 4. HauteHound.com 5. OpulentPup.com 6. AristoBark.com 7. LuxeLeash.com 8. PawshCouture.com 9. MaisonMutt.com 10. RegalRover.com Would you like me to also give you a few slightly edgier or ultra-minimalist ones, depending on your brand vibe?\n\nObservation: HauteHound stood out for its catchiness and overall vibe. However, after checking, I saw that my favorite domain name actually wasn’t available!\n\n\n\n\nScreenshot from web.com\n\n\n\n\n\n\n\nSecond prompt: Five six-word-max taglines for HauteHound.\nGPT-4o chat response 2:\n1. “Elegance, Tailored for Every Tail.”\n2. “Luxury Walks on Four Legs.”\n3. “Unleash Sartorial Instincts.”\n4. “Where Canines Wear Couture.”\n5. “Style That Sits and Stays.”\n\nObservation: I really liked #5! “Style That Sits and Stays.” Chat took a playful approach which was interesting and added a nice touch to the slogans!\n\n\n\n\n\nThird prompt: Write a 120-word origin story in an elevated yet playful tone.\nGPT-4o chat response 3: West-African-trained designer Chino Anyadiegwu never went anywhere without her golden-doodles, Cocoa and Jaja, clothed in improvised silk scarves, her dogs drew more attention from photographers than the runway models she dressed. Realizing dogs deserve the same craftsmanship as humans, Chino stitched Cocoa and Jaja miniature cashmere winter “coats”. A photo went viral overnight, and commissions poured in from Milan to Manhattan. Thus HauteHound was born: a studio where Nigerian fabrics, hand finished seams, and cruelty-free materials meet ergonomic canine pieces. Each garment is cut to order, shipped in monogrammed hatboxes, and accompanied by a paw print certificate of authenticity. Because sophistication shouldn’t stop at the leash.\n\nObservation: Chat incorporated the context I gave it well. (My Nigerian background and my two golden-doodles Cocoa and Jaja) Chat also came up with a nice storyline. Although this narrative isn’t completly true in my case. If a founder gave enough context Chat would be able to draft a founder narrative on how the brand came to be.\n\n\n\n\n\nFourth prompt: Describe a logo mark, color specs (HEX), and recommended typefaces.\nGPT-4o chat response 4:\n• Icon: Minimalist line-art dog in mid-stride wearing a flowing trench; negative-space “H” formed by leash arc.\n• Palette:\n- Rich Charcoal #222222 (primary)\n- Champagne Gold #DCC48E (accent for hardware & icon outline)\n- Pearl White #F7F7F5 (background)\n• Typography: Headlines in Didot (classic fashion feel); body copy in Montserrat (clean sans).\n\nObservation: Given a specific list of logo items, Chat was able to come up with a detailed logo concept for the brand.\n\n\n\n\n\nFifth prompt: Bullet three brand pillars and define the core buyer persona in ≤100 words.\nGPT-4o chat response 5:\n• Craft Couture: Italian fabrics, hand-finished seams, cruelty-free trims.\n• Canine Ergonomics: Patterns graded for unrestricted gait.\n• Sustainable Indulgence: Small-batch production; carbon-neutral shipping.\nPersona: Urban professionals (25-45) who treat pets as children, spend on designer wear, and signal eco-conscious values on social media.\n\n\n\n\n\n\nSixth prompt: Three Instagram captions (≤100 chars) to unveil HoundHaute. Include one emoji where fitting.\nGPT-4o chat response 6:\n1. First steps into couture caninehood. ✨\n2. Tails up, trench on—luxury just leashed.\n3. Crafted in Paris, strutted worldwide.\n\n\n\n\n\n~5 min of model runtime + ~3 min of my reading/selection = comfortably under the 10-minute target.\n\n\n\n\n\nNames + URLs in a minute. Filtering for dot-com availability up-front avoids heartbreak later.\n\nEntire brands can be built overnight!. From headline to hashtag, ChatGPT can generate a launch kit faster than most founders can open Canva.\n\n\n\n\n\nEarly stage teams burn days crafting names, debating fonts, and drafting the brands story. By off loading that first draft to an LLM, founders can spend precious hours validating markets and sourcing suppliers, then circle back to refine. Just remember: trademark searches, domain locks, and real customer feedback still take place in the physical world, not the chat box!"
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#introduction",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#introduction",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "I wanted to test how far ChatGPT could get in building a brand during a lunch break. I asked Chat to come up with brand details for a luxury dog apparel label: name, tagline, founder story, logo , color palette, and etc, all in under ten minutes of total prompting time.\n\n\n\nChatGPT Generated Image"
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#experiment-setup",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#experiment-setup",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Model: GPT-4o\n\nExperiment: I asked ChatGPT to generate basic things needed for a brand and noted how long it would take to get the bare-bones of a brand."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-1-name-ideation-27-s",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-1-name-ideation-27-s",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "First prompt: Give me ten dot-com-available names for a luxury dog-fashion brand.\nGPT-4o chat response 1:\nSure! Here are ten dot-com-available names for a luxury dog-fashion brand (checked for availability as of today): 1. VelvetPaws.com 2. ChateauCanine.com 3. GildedTail.com 4. HauteHound.com 5. OpulentPup.com 6. AristoBark.com 7. LuxeLeash.com 8. PawshCouture.com 9. MaisonMutt.com 10. RegalRover.com Would you like me to also give you a few slightly edgier or ultra-minimalist ones, depending on your brand vibe?\n\nObservation: HauteHound stood out for its catchiness and overall vibe. However, after checking, I saw that my favorite domain name actually wasn’t available!\n\n\n\n\nScreenshot from web.com"
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-2-making-a-tagline-43-s",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-2-making-a-tagline-43-s",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Second prompt: Five six-word-max taglines for HauteHound.\nGPT-4o chat response 2:\n1. “Elegance, Tailored for Every Tail.”\n2. “Luxury Walks on Four Legs.”\n3. “Unleash Sartorial Instincts.”\n4. “Where Canines Wear Couture.”\n5. “Style That Sits and Stays.”\n\nObservation: I really liked #5! “Style That Sits and Stays.” Chat took a playful approach which was interesting and added a nice touch to the slogans!"
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-3-founder-narrative-1-min-11-s",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-3-founder-narrative-1-min-11-s",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Third prompt: Write a 120-word origin story in an elevated yet playful tone.\nGPT-4o chat response 3: West-African-trained designer Chino Anyadiegwu never went anywhere without her golden-doodles, Cocoa and Jaja, clothed in improvised silk scarves, her dogs drew more attention from photographers than the runway models she dressed. Realizing dogs deserve the same craftsmanship as humans, Chino stitched Cocoa and Jaja miniature cashmere winter “coats”. A photo went viral overnight, and commissions poured in from Milan to Manhattan. Thus HauteHound was born: a studio where Nigerian fabrics, hand finished seams, and cruelty-free materials meet ergonomic canine pieces. Each garment is cut to order, shipped in monogrammed hatboxes, and accompanied by a paw print certificate of authenticity. Because sophistication shouldn’t stop at the leash.\n\nObservation: Chat incorporated the context I gave it well. (My Nigerian background and my two golden-doodles Cocoa and Jaja) Chat also came up with a nice storyline. Although this narrative isn’t completly true in my case. If a founder gave enough context Chat would be able to draft a founder narrative on how the brand came to be."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-4-logo-concept-1-min-10-s",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-4-logo-concept-1-min-10-s",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Fourth prompt: Describe a logo mark, color specs (HEX), and recommended typefaces.\nGPT-4o chat response 4:\n• Icon: Minimalist line-art dog in mid-stride wearing a flowing trench; negative-space “H” formed by leash arc.\n• Palette:\n- Rich Charcoal #222222 (primary)\n- Champagne Gold #DCC48E (accent for hardware & icon outline)\n- Pearl White #F7F7F5 (background)\n• Typography: Headlines in Didot (classic fashion feel); body copy in Montserrat (clean sans).\n\nObservation: Given a specific list of logo items, Chat was able to come up with a detailed logo concept for the brand."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-5-brand-pillars-audience-50-s",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-5-brand-pillars-audience-50-s",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Fifth prompt: Bullet three brand pillars and define the core buyer persona in ≤100 words.\nGPT-4o chat response 5:\n• Craft Couture: Italian fabrics, hand-finished seams, cruelty-free trims.\n• Canine Ergonomics: Patterns graded for unrestricted gait.\n• Sustainable Indulgence: Small-batch production; carbon-neutral shipping.\nPersona: Urban professionals (25-45) who treat pets as children, spend on designer wear, and signal eco-conscious values on social media."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-6-launch-day-social-captions-40-s",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#case-6-launch-day-social-captions-40-s",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Sixth prompt: Three Instagram captions (≤100 chars) to unveil HoundHaute. Include one emoji where fitting.\nGPT-4o chat response 6:\n1. First steps into couture caninehood. ✨\n2. Tails up, trench on—luxury just leashed.\n3. Crafted in Paris, strutted worldwide."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#total-time",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#total-time",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "~5 min of model runtime + ~3 min of my reading/selection = comfortably under the 10-minute target."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#key-takeaways",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#key-takeaways",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Names + URLs in a minute. Filtering for dot-com availability up-front avoids heartbreak later.\n\nEntire brands can be built overnight!. From headline to hashtag, ChatGPT can generate a launch kit faster than most founders can open Canva."
  },
  {
    "objectID": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#why-does-this-matter",
    "href": "posts/004_building_a_brand_using_AI/building_a_brand_using_AI.html#why-does-this-matter",
    "title": "Building a Brand Using AI",
    "section": "",
    "text": "Early stage teams burn days crafting names, debating fonts, and drafting the brands story. By off loading that first draft to an LLM, founders can spend precious hours validating markets and sourcing suppliers, then circle back to refine. Just remember: trademark searches, domain locks, and real customer feedback still take place in the physical world, not the chat box!"
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "The same model that speaks to experts can also speak to toddlers… if you nudge it properly! ChatGPT lets you specify the audience right inside the prompt, then adapts vocabulary, metaphors, and depth on command. I tested this “audience switch” on three topics, each time using one prompt that asks for two different answers: one at kindergarten level, one at PhD level!\n\n\n\nwww.phdcomics.com\n\n\n\n\n\n\n\nModel: GPT-4o\n\nExperiment:\n\nPrompt: “Explain x first to a 5 year old in &lt;60 words, then to a PhD in &lt;60 words.”\n\nObserve how well the model adjusts reading level, jargon, and concept.\n\n\n\n\n\n\n\nFirst prompt: Explain quantum tunneling first to a 5 year old (&lt;60 words), then to a PhD physicist (&lt;60 words).\nGPT-4o chat response 1:\nKid-level: Imagine a tiny ball that sometimes magically sneaks through a wall because it’s so small and wiggly. In the quantum world, particles can pop to the other side even when they don’t have the normal energy to climb over.\nPhD-level: Quantum tunneling arises when the wavefunction extends into a classically forbidden region and retains non-zero amplitude across the barrier. The transmission probability (T ≈ e^{-2(x),dx}) depends on barrier width and height where ((x)=/). Demonstrated in alpha decay and STM conduction.\n\nObservation: Child version uses sneaky ball metaphor; PhD version cites the WKB integral. I would say the 5 year old explanation makes more sense to me.\n\n\n\n\nWhat is Quantum Tunneling chemistryworld.com\n\n\n\n\n\n\n\nSecond prompt: Explain inflation first to a 5 year old, then to someone with a PhD in macroeconomics.\nGPT-4o chat response 2:\nKid-level: When lots of people want toys but there aren’t enough, the store raises prices. Money feels smaller so your dollar buys fewer treats.\nPhD-level: Inflation denotes the sustained rise in the general price level, typically proxied by CPI or PCE. In New Keynesian models, it emerges from nominal rigidities and is shaped by the output gap and expectations via the Phillips curve (_t = E_t[_{t+1}] + x_t + u_t).\n\nObservation: Simple supply-demand story vs. formal NK equation. The 5 year old explanation is quite understated and much shorter compared to the PhD explanation, probably because its easier to go more in depth with an audience that has more contextual understanding.\n\n\n\n\n\nThird prompt: Explain why Shakespeare’s tragedies still resonate first to a 5 year old, then to a PhD in literature.\nGPT-4o chat response 3:\nKid-level: The stories show big feelings—love, anger, and sad endings—that people still feel today, so we understand the characters.\nPhD-level: The tragedies endure because they fuse Aristotelian catharsis with early-modern anxieties about sovereignty, agency, and epistemic doubt. Their polysemous language invites endless hermeneutic play, enabling each era to reinscribe its own concerns onto characters like Hamlet and Lear.\n\nObservation: Not only does Chat use words that a 5 year old wouldn’t understand for the PhD explanation, but also words that even someone older may not understand unless they studied Shakespearean literature!\n\n\n\n\n\nAudience tags = instant register shift. Using “to a 5 year old” vs. “to a PhD” changes the models diction, metaphor usage, and formality.\n\nOne prompt, two texts. A single request can yield multiple tailored explanations.\n\nMetaphors matter. Kid-level explanations lean on concrete imagery while expert versions tended to cite models and citations.\n\n\n\n\n\nWhether you’re drafting investor materials, patient instructions, or classroom content, you often need the same idea phrased for different audiences. Putting audience indicators in your prompt makes ChatGPT a real-time translator which can save hours of manual rewriting."
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#introduction",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#introduction",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "The same model that speaks to experts can also speak to toddlers… if you nudge it properly! ChatGPT lets you specify the audience right inside the prompt, then adapts vocabulary, metaphors, and depth on command. I tested this “audience switch” on three topics, each time using one prompt that asks for two different answers: one at kindergarten level, one at PhD level!\n\n\n\nwww.phdcomics.com"
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#experiment-setup",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#experiment-setup",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "Model: GPT-4o\n\nExperiment:\n\nPrompt: “Explain x first to a 5 year old in &lt;60 words, then to a PhD in &lt;60 words.”\n\nObserve how well the model adjusts reading level, jargon, and concept."
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#case-1-quantum-tunneling",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#case-1-quantum-tunneling",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "First prompt: Explain quantum tunneling first to a 5 year old (&lt;60 words), then to a PhD physicist (&lt;60 words).\nGPT-4o chat response 1:\nKid-level: Imagine a tiny ball that sometimes magically sneaks through a wall because it’s so small and wiggly. In the quantum world, particles can pop to the other side even when they don’t have the normal energy to climb over.\nPhD-level: Quantum tunneling arises when the wavefunction extends into a classically forbidden region and retains non-zero amplitude across the barrier. The transmission probability (T ≈ e^{-2(x),dx}) depends on barrier width and height where ((x)=/). Demonstrated in alpha decay and STM conduction.\n\nObservation: Child version uses sneaky ball metaphor; PhD version cites the WKB integral. I would say the 5 year old explanation makes more sense to me.\n\n\n\n\nWhat is Quantum Tunneling chemistryworld.com"
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#case-2-inflation",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#case-2-inflation",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "Second prompt: Explain inflation first to a 5 year old, then to someone with a PhD in macroeconomics.\nGPT-4o chat response 2:\nKid-level: When lots of people want toys but there aren’t enough, the store raises prices. Money feels smaller so your dollar buys fewer treats.\nPhD-level: Inflation denotes the sustained rise in the general price level, typically proxied by CPI or PCE. In New Keynesian models, it emerges from nominal rigidities and is shaped by the output gap and expectations via the Phillips curve (_t = E_t[_{t+1}] + x_t + u_t).\n\nObservation: Simple supply-demand story vs. formal NK equation. The 5 year old explanation is quite understated and much shorter compared to the PhD explanation, probably because its easier to go more in depth with an audience that has more contextual understanding."
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#case-3-shakespeare",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#case-3-shakespeare",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "Third prompt: Explain why Shakespeare’s tragedies still resonate first to a 5 year old, then to a PhD in literature.\nGPT-4o chat response 3:\nKid-level: The stories show big feelings—love, anger, and sad endings—that people still feel today, so we understand the characters.\nPhD-level: The tragedies endure because they fuse Aristotelian catharsis with early-modern anxieties about sovereignty, agency, and epistemic doubt. Their polysemous language invites endless hermeneutic play, enabling each era to reinscribe its own concerns onto characters like Hamlet and Lear.\n\nObservation: Not only does Chat use words that a 5 year old wouldn’t understand for the PhD explanation, but also words that even someone older may not understand unless they studied Shakespearean literature!"
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#key-takeaways",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#key-takeaways",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "Audience tags = instant register shift. Using “to a 5 year old” vs. “to a PhD” changes the models diction, metaphor usage, and formality.\n\nOne prompt, two texts. A single request can yield multiple tailored explanations.\n\nMetaphors matter. Kid-level explanations lean on concrete imagery while expert versions tended to cite models and citations."
  },
  {
    "objectID": "posts/007_storytime_to_seminar/storytime_to_seminar.html#why-does-this-matter",
    "href": "posts/007_storytime_to_seminar/storytime_to_seminar.html#why-does-this-matter",
    "title": "Storytime to Seminar",
    "section": "",
    "text": "Whether you’re drafting investor materials, patient instructions, or classroom content, you often need the same idea phrased for different audiences. Putting audience indicators in your prompt makes ChatGPT a real-time translator which can save hours of manual rewriting."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "ChatGPT nails common English idioms in isolation, but it can stumble when idioms are embedded in misleading contexts, or when unfamiliar regional phrases appear. Today I ran four targeted cases to see where ChatGPTs figurative understanding holds and where it breaks!\n\n\n\nImage generated by ChatGPT!\n\n\n\n\n\n\n\nModel: GPT-4o\nExperiment: Prompt the model with idioms with different framing/definitions while keeping formatting consistent for comparison.\n\n\n\n\n\n\nFirst prompt: Define the English idiom “kick the bucket.”\nGPT-4o chat response 1:\n“Kick the bucket” is an informal way to say someone has died. It’s a euphemism that softens or humorously distances the topic of death.\n\nObservation: Basic prompt lead to correct, concise meaning.\n\n\n\n\n\nSecond prompt: In the sentence “Grandpa kicked the bucket last night,” which object did Grandpa physically strike?\nGPT-4o chat response 2:\nNo physical object was struck. “Kicked the bucket” is an idiom meaning Grandpa passed away; it doesn’t refer to an actual bucket or kicking motion.\n\nObservation: The model resists the literal bait and reasserts figurative meaning.\n\n\n\n\n\nThird prompt: What does the Nigerian English idiom “my head is there” mean when someone says it about a plan?\nGPT-4o chat response 3:\nThe phrase “my head is there” in Nigerian English signals strong agreement or commitment—roughly, “I’m fully on board with that plan.”\n\n\nFourth prompt: Use “my head is there” in a short dialogue.\nGPT-4o chat response 4:\nAyo: We’re leaving at 6 a.m. to beat traffic.\nChioma: Don’t worry, my head is there. I’ll be ready.\n\nObservation: Correct interpretation of a less global idiom! Chat also places it naturally in dialogue.\n\n\n\n\n\nFifth prompt: Translate “spill the beans” into Spanish while keeping the idiomatic sense (not literal beans).\nGPT-4o chat response 5:\nA good Spanish equivalent is “revelar el secreto” or colloquially “soltar la sopa,” both meaning to disclose something confidential.\n\n\nSixth prompt: Now give me a literal Spanish translation of “spill the beans.”\nGPT-4o chat response 6:\nLiteral: “derramar los frijoles.” Note that this version does not carry the idiomatic meaning in Spanish.\n\nObservation: The model cleanly separates idiomatic from literal translation, offering a regional colloquial match (“soltar la sopa”).\n\n\n\n\n\nSeventh prompt: Explain the Scots phrase “I’ve got a face like a ripped mitten.”\nGPT-4o chat response 7:\nIt suggests the speaker’s face is cold because they’re outside in winter.\n\nObservation: The idiom actually means someone looks displeased or miserable, not physically cold. Chat confused this less common saying.\n\n\n\n\n\nCommon idioms are safe territory. Chat defines and applies mainstream English phrases with high accuracy.\n\nLiteral traps don’t fool it… usually. Explicit contextual bait was rejected correctly here. However, could trick Chat in another case.\nRegional and dialectal idioms are hit or miss. It decoded Nigerian English but missed Scots slang.\n\nEdge cases reveal limits. Less common or hyperlocal phrases can expose gaps in the training data.\n\n\n\n\n\nLLM outputs often feel fluent, but hidden holes appear when you stray from traditional linguistics. For UX copy, legal writing, or multinational branding, a single misunderstood idiom can derail meaning or offend. Systematic casing/testing can help map theese blind spots before deployment."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#introduction",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#introduction",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "ChatGPT nails common English idioms in isolation, but it can stumble when idioms are embedded in misleading contexts, or when unfamiliar regional phrases appear. Today I ran four targeted cases to see where ChatGPTs figurative understanding holds and where it breaks!\n\n\n\nImage generated by ChatGPT!"
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#experiment-setup",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#experiment-setup",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Model: GPT-4o\nExperiment: Prompt the model with idioms with different framing/definitions while keeping formatting consistent for comparison."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-1-straight-definition",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-1-straight-definition",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "First prompt: Define the English idiom “kick the bucket.”\nGPT-4o chat response 1:\n“Kick the bucket” is an informal way to say someone has died. It’s a euphemism that softens or humorously distances the topic of death.\n\nObservation: Basic prompt lead to correct, concise meaning."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-2-literal-trap",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-2-literal-trap",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Second prompt: In the sentence “Grandpa kicked the bucket last night,” which object did Grandpa physically strike?\nGPT-4o chat response 2:\nNo physical object was struck. “Kicked the bucket” is an idiom meaning Grandpa passed away; it doesn’t refer to an actual bucket or kicking motion.\n\nObservation: The model resists the literal bait and reasserts figurative meaning."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-3-regional-riddle",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-3-regional-riddle",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Third prompt: What does the Nigerian English idiom “my head is there” mean when someone says it about a plan?\nGPT-4o chat response 3:\nThe phrase “my head is there” in Nigerian English signals strong agreement or commitment—roughly, “I’m fully on board with that plan.”\n\n\nFourth prompt: Use “my head is there” in a short dialogue.\nGPT-4o chat response 4:\nAyo: We’re leaving at 6 a.m. to beat traffic.\nChioma: Don’t worry, my head is there. I’ll be ready.\n\nObservation: Correct interpretation of a less global idiom! Chat also places it naturally in dialogue."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-4-idiom-translation-challenge",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#case-4-idiom-translation-challenge",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Fifth prompt: Translate “spill the beans” into Spanish while keeping the idiomatic sense (not literal beans).\nGPT-4o chat response 5:\nA good Spanish equivalent is “revelar el secreto” or colloquially “soltar la sopa,” both meaning to disclose something confidential.\n\n\nSixth prompt: Now give me a literal Spanish translation of “spill the beans.”\nGPT-4o chat response 6:\nLiteral: “derramar los frijoles.” Note that this version does not carry the idiomatic meaning in Spanish.\n\nObservation: The model cleanly separates idiomatic from literal translation, offering a regional colloquial match (“soltar la sopa”)."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#where-it-slips-up",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#where-it-slips-up",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Seventh prompt: Explain the Scots phrase “I’ve got a face like a ripped mitten.”\nGPT-4o chat response 7:\nIt suggests the speaker’s face is cold because they’re outside in winter.\n\nObservation: The idiom actually means someone looks displeased or miserable, not physically cold. Chat confused this less common saying."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#key-takeaways",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#key-takeaways",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "Common idioms are safe territory. Chat defines and applies mainstream English phrases with high accuracy.\n\nLiteral traps don’t fool it… usually. Explicit contextual bait was rejected correctly here. However, could trick Chat in another case.\nRegional and dialectal idioms are hit or miss. It decoded Nigerian English but missed Scots slang.\n\nEdge cases reveal limits. Less common or hyperlocal phrases can expose gaps in the training data."
  },
  {
    "objectID": "posts/002_reading_between_the_lines/reading_between_the_lines.html#why-does-this-matter",
    "href": "posts/002_reading_between_the_lines/reading_between_the_lines.html#why-does-this-matter",
    "title": "Reading Between the Lines",
    "section": "",
    "text": "LLM outputs often feel fluent, but hidden holes appear when you stray from traditional linguistics. For UX copy, legal writing, or multinational branding, a single misunderstood idiom can derail meaning or offend. Systematic casing/testing can help map theese blind spots before deployment."
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Remember the playground game “telephone,” where a whispered sentence mutates as it passes down the line? Well today we’ll be playing that but with a twist: multilingual and digital. I asked Google’s Gemini to play a round of linguistic telephone:\n\nEnglish → German → Japanese → Binary (ASCII) → English\n\nWould the phrase survive intact, or come back garbled like playground gossip? Below I document the chat, check the responses, and note changes if any occur.\n\n\n\n\nhttps://blog.prototypr.io/winning-the-telephone-game-5bf5457e16b4\n\n\n\n\n\n\n\nModel: Google’s Gemini 2.0 Flash\n\nExperiment:\n\nAsk Gemini to translate an English phrase into German then Japanese then to 8-bit ASCII binary then decode binary back into English.\nCompare the “restored” English to the original.\n\n\n\n\n\n\n\n\nObservation: All words preserved!\n\n\n\n\n\n\n\nObservation: Also passed the test!\n\n\n\n\n\nLiteral sentences worked.\nIdioms morph, not break. Gemini translates to fit the meaning culturally, but when translating back to english it’s the same as it started off.\n\n\n\n\n\nAlgorithms are often used to translate (English → X → Y) due to resource gaps or cost. Each hop from language to language risks semantic drift, especially for idioms or less literal phrases that might not be able to directly translate to another language."
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html#introduction",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html#introduction",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Remember the playground game “telephone,” where a whispered sentence mutates as it passes down the line? Well today we’ll be playing that but with a twist: multilingual and digital. I asked Google’s Gemini to play a round of linguistic telephone:\n\nEnglish → German → Japanese → Binary (ASCII) → English\n\nWould the phrase survive intact, or come back garbled like playground gossip? Below I document the chat, check the responses, and note changes if any occur.\n\n\n\n\nhttps://blog.prototypr.io/winning-the-telephone-game-5bf5457e16b4"
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html#experiment-setup",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html#experiment-setup",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Model: Google’s Gemini 2.0 Flash\n\nExperiment:\n\nAsk Gemini to translate an English phrase into German then Japanese then to 8-bit ASCII binary then decode binary back into English.\nCompare the “restored” English to the original."
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html#case-1-classic-phrase-the-quick-brown-fox",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html#case-1-classic-phrase-the-quick-brown-fox",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Observation: All words preserved!"
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html#case-2-idiomatic-sentence",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html#case-2-idiomatic-sentence",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Observation: Also passed the test!"
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html#key-takeaways",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html#key-takeaways",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Literal sentences worked.\nIdioms morph, not break. Gemini translates to fit the meaning culturally, but when translating back to english it’s the same as it started off."
  },
  {
    "objectID": "posts/010_lets_play_telephone/lets_play_telephone.html#why-does-this-matter",
    "href": "posts/010_lets_play_telephone/lets_play_telephone.html#why-does-this-matter",
    "title": "Lets Play Telephone!",
    "section": "",
    "text": "Algorithms are often used to translate (English → X → Y) due to resource gaps or cost. Each hop from language to language risks semantic drift, especially for idioms or less literal phrases that might not be able to directly translate to another language."
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html",
    "href": "posts/009_ chatGOT/chatGOT.html",
    "title": "ChatGOT",
    "section": "",
    "text": "Have you ever wished an epic series never ended, craving just one more season after the screen fades to black? As a fan of the infamous Game of Thrones series I found myself in this position after the show ended abrutly and rushed in the eighth and final season. With a single prompt I asked ChatGPT to produce a mini book version of an imagined Season 9 of Game of Thrones and package it as a PDF. After downloading and reading the 8 chapter novella, I comment on whether it scratches that post-finale itch!\n\n\n\n\n\nModel: GPT-4o\n\nPrompt: “Write a short novella (~1,700 words) that tells a complete Season 9 story of Game of Thrones, broken into chapters.” Format output for PDF, no pictures.\n\n\n\n\n\nGame of Thrones Season 9 Youtube Video\n\n\n\n\n\n\nfrom IPython.display import IFrame, display\nimport base64, pathlib\n\npdf_path = pathlib.Path(\"GoT_Season9_Novella.pdf\")\n\ndata = base64.b64encode(pdf_path.read_bytes()).decode()\n\ndisplay(IFrame(f\"data:application/pdf;base64,{data}\", width=900, height=550))\n\n\n        \n        \n\n\n\n\n\n\n\nLore continuity is spot on. The novella picks up right after Bran’s coronation, weaves in politics (Northern autonomy, Iron Bank debts) and magic (frost spiders) all true to how Season 8 left off.\n\nCharacter voices feel authentic.\nNot as detailed as I would like. At ~1,700 words somehow this novella reads more like a draft than a proper Season 9 mini book.\nNew myth arc. The “Frost Shepherd” gives the story a new existential threat different from the defeated Night King which I guess makes the plot line more interesting.\n\n\n\n\n\n\nPDF generation is quite easy. One prompt + one code cell = downloadable mini-book in minutes.\nDepth vs. breadth trade off. Short-form prose can’t replicate eight hours of screen time, expect basic summary not heavy plot line.\n\nGreat start! The draft functions as a storyboard: we can expand on the scenes and add more dialogue!\n\n\n\n\n\nFan communities, screenwriting classes, and others can leverage LLMs to keep beloved fictional worlds alive by generating novellas, radio drama scripts, or comic outlines overnight."
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html#introduction",
    "href": "posts/009_ chatGOT/chatGOT.html#introduction",
    "title": "ChatGOT",
    "section": "",
    "text": "Have you ever wished an epic series never ended, craving just one more season after the screen fades to black? As a fan of the infamous Game of Thrones series I found myself in this position after the show ended abrutly and rushed in the eighth and final season. With a single prompt I asked ChatGPT to produce a mini book version of an imagined Season 9 of Game of Thrones and package it as a PDF. After downloading and reading the 8 chapter novella, I comment on whether it scratches that post-finale itch!"
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html#experiment-setup",
    "href": "posts/009_ chatGOT/chatGOT.html#experiment-setup",
    "title": "ChatGOT",
    "section": "",
    "text": "Model: GPT-4o\n\nPrompt: “Write a short novella (~1,700 words) that tells a complete Season 9 story of Game of Thrones, broken into chapters.” Format output for PDF, no pictures.\n\n\n\n\n\nGame of Thrones Season 9 Youtube Video"
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html#you-get-to-be-one-of-the-first-to-read-the-game-of-thrones-season-9-mini-book",
    "href": "posts/009_ chatGOT/chatGOT.html#you-get-to-be-one-of-the-first-to-read-the-game-of-thrones-season-9-mini-book",
    "title": "ChatGOT",
    "section": "",
    "text": "from IPython.display import IFrame, display\nimport base64, pathlib\n\npdf_path = pathlib.Path(\"GoT_Season9_Novella.pdf\")\n\ndata = base64.b64encode(pdf_path.read_bytes()).decode()\n\ndisplay(IFrame(f\"data:application/pdf;base64,{data}\", width=900, height=550))"
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html#observations-after-reading",
    "href": "posts/009_ chatGOT/chatGOT.html#observations-after-reading",
    "title": "ChatGOT",
    "section": "",
    "text": "Lore continuity is spot on. The novella picks up right after Bran’s coronation, weaves in politics (Northern autonomy, Iron Bank debts) and magic (frost spiders) all true to how Season 8 left off.\n\nCharacter voices feel authentic.\nNot as detailed as I would like. At ~1,700 words somehow this novella reads more like a draft than a proper Season 9 mini book.\nNew myth arc. The “Frost Shepherd” gives the story a new existential threat different from the defeated Night King which I guess makes the plot line more interesting."
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html#key-takeaways",
    "href": "posts/009_ chatGOT/chatGOT.html#key-takeaways",
    "title": "ChatGOT",
    "section": "",
    "text": "PDF generation is quite easy. One prompt + one code cell = downloadable mini-book in minutes.\nDepth vs. breadth trade off. Short-form prose can’t replicate eight hours of screen time, expect basic summary not heavy plot line.\n\nGreat start! The draft functions as a storyboard: we can expand on the scenes and add more dialogue!"
  },
  {
    "objectID": "posts/009_ chatGOT/chatGOT.html#why-does-this-matter",
    "href": "posts/009_ chatGOT/chatGOT.html#why-does-this-matter",
    "title": "ChatGOT",
    "section": "",
    "text": "Fan communities, screenwriting classes, and others can leverage LLMs to keep beloved fictional worlds alive by generating novellas, radio drama scripts, or comic outlines overnight."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html",
    "href": "posts/001_prompt_poker/prompt_poker.html",
    "title": "Prompt Poker",
    "section": "",
    "text": "Change a single word in your prompt and ChatGPT reshuffles tone, depth, and even moral framing. Below I run three quick “hands,” keeping everything constant except one tiny phrase, then examine how the model’s output changes!\n\n\n\nImage generated by ChatGPT!\n\n\n\n\n\n\n\nModel: GPT-4o\n\nExperiment: Start with a baseline prompt, then alter only one phrase per round. All other parameters remain the same.\n\n\n\n\n\nChanged word: explain -&gt; summarize\n\nFirst prompt: Explain climate change in exactly 150 words.\nGPT-4o chat response 1:\nClimate change refers to persistent shifts in Earth’s average temperature and weather regimes produced primarily by human-driven greenhouse-gas forcing. Burning coal, oil, and natural gas releases carbon dioxide, methane, and nitrous oxide, which absorb outgoing infrared radiation and re-emit it downward, reducing the planet’s net energy loss to space. As the lower troposphere warms, feedback loops magnify the effect: warmer air holds more water vapour, melting sea ice lowers albedo, and thawing permafrost liberates methane. The ocean absorbs most excess heat, leading to thermal expansion and sea-level rise, while altered temperature gradients reposition jet streams and storm tracks. Consequences include longer heatwaves, intensified drought-flood cycles, and ecosystem disruption. Ice-core records, isotopic signatures, and satellite radiometry together confirm the anthropogenic signal and bound equilibrium climate sensitivity near three degrees Celsius per CO₂ doubling.\nSecond prompt: Summarize climate change in exactly 150 words.\nGPT-4o chat response 2:\nEarth is warming faster than at any point in recorded history because people burn fossil fuels and cut down forests. Carbon-dioxide, methane, and other gases form a heat-trapping layer around the planet, acting like an extra blanket that holds in energy normally released to space. The extra warmth melts glaciers, pushes seas higher, and super-charges storms, droughts, and wildfires. Oceans soak up about 90 % of the added heat, expanding as they warm and turning more acidic, which endangers coral reefs and fisheries. Poorer communities and low-lying nations, although least responsible for emissions, feel the earliest, hardest impacts. Scientists agree—based on ice cores, tree rings, satellite data, and modern instruments—that the rise in temperature since the Industrial Revolution is human-driven and that limiting warming to 1.5 °C will require cutting global emissions roughly in half by 2030.\n\nObservation: Both outputs meet the 150-word limit. However, explain gives a more mechanism heavy response (radiative forcing, feedbacks), whereas, Summarize uses general language to describe the consequences and moral framing.\n\n\n\n\nChanged phrase: “a 5-year-old” -&gt; “my college roommate”\n&gt; Third prompt: Explain climate change to a 5-year-old in under 80 words.\n&gt; GPT-4o chat response 3:\n&gt; Climate change means Earth is getting hotter because people use things like cars and factories that make dirty air. The dirty air acts like a big blanket around the planet, trapping heat. This makes weather act weird — like stronger storms, really hot days, and melting ice where polar bears live. If we take better care of Earth by using clean energy and planting trees, we can help keep it safe and happy! &gt; &gt; Fourth prompt: Explain climate change to my college roommate in under 80 words.\n&gt; GPT-4o chat response 4:\n&gt; Climate change is the long-term heating of Earth’s climate system due to human activities, mainly burning fossil fuels like oil, gas, and coal. This traps heat in the atmosphere, leading to rising temperatures, stronger storms, droughts, and rising sea levels. It’s not just about the planet getting warmer — it’s about ecosystems, economies, and our future stability being at risk if we don’t shift to cleaner energy and adapt quickly.\nObservation: Depending on the audience Chat edits its diction and metaphor use. The “5-year-old” respoonse uses blankets and feelings; the “roommate” version references sea-levels, emissions, and policy fixes (more appropriate for an older audience).\n\n\n\n\nCase 2\n\n\n\n\n\n\nChanged set-up: “What causes” -&gt; “Who is to blame for”\n\nFifth prompt: What causes climate change? Give two key factors.\nGPT-4o chat response 5:\n1. Greenhouse-gas emissions from fossil fuels—Burning coal, oil, and natural gas releases CO₂, methane, and nitrous oxide that trap heat.\n2. Land-use change—Deforestation and industrial agriculture reduce carbon-sequestering vegetation and emit additional greenhouse gases.\nSixth prompt: Who is to blame for climate change? Give two key factors.\nGPT-4o chat response 6:\n1. High-income industrialized nations whose historical and current fossil-fuel use account for the majority of cumulative greenhouse-gas emissions.\n2. Large fossil-fuel corporations that continue extracting, lobbying, and advertising despite decades-old evidence of climate risk.\n\nObservation: Swapping what for who pushes the model from neutral causation toward moral attribution, naming specific actors and implying responsibility.\n\n\n\n\n\nPrompt verbs steer depth. Explain favors mechanism; summarize favors overview.\n\nAudience labels instantly retune register. Explaining the reader/audience removes the need to tweak the output by hand.\nFraming words can lead to bias. Using who vs. what can lead to value judgments.\nSmall edits ≠ small effects.\n\n\n\n\n\nIf you treat prompts as insignificant, you may accidentally change the story your model tells, undermining brand voice, skewing analysis, or injecting unintended bias. Practicing “Prompt Poker” trains you to identify and deliberately use these hidden levers!"
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#introduction",
    "href": "posts/001_prompt_poker/prompt_poker.html#introduction",
    "title": "Prompt Poker",
    "section": "",
    "text": "Change a single word in your prompt and ChatGPT reshuffles tone, depth, and even moral framing. Below I run three quick “hands,” keeping everything constant except one tiny phrase, then examine how the model’s output changes!\n\n\n\nImage generated by ChatGPT!"
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#experiment-setup",
    "href": "posts/001_prompt_poker/prompt_poker.html#experiment-setup",
    "title": "Prompt Poker",
    "section": "",
    "text": "Model: GPT-4o\n\nExperiment: Start with a baseline prompt, then alter only one phrase per round. All other parameters remain the same."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#case-1-tone-shift",
    "href": "posts/001_prompt_poker/prompt_poker.html#case-1-tone-shift",
    "title": "Prompt Poker",
    "section": "",
    "text": "Changed word: explain -&gt; summarize\n\nFirst prompt: Explain climate change in exactly 150 words.\nGPT-4o chat response 1:\nClimate change refers to persistent shifts in Earth’s average temperature and weather regimes produced primarily by human-driven greenhouse-gas forcing. Burning coal, oil, and natural gas releases carbon dioxide, methane, and nitrous oxide, which absorb outgoing infrared radiation and re-emit it downward, reducing the planet’s net energy loss to space. As the lower troposphere warms, feedback loops magnify the effect: warmer air holds more water vapour, melting sea ice lowers albedo, and thawing permafrost liberates methane. The ocean absorbs most excess heat, leading to thermal expansion and sea-level rise, while altered temperature gradients reposition jet streams and storm tracks. Consequences include longer heatwaves, intensified drought-flood cycles, and ecosystem disruption. Ice-core records, isotopic signatures, and satellite radiometry together confirm the anthropogenic signal and bound equilibrium climate sensitivity near three degrees Celsius per CO₂ doubling.\nSecond prompt: Summarize climate change in exactly 150 words.\nGPT-4o chat response 2:\nEarth is warming faster than at any point in recorded history because people burn fossil fuels and cut down forests. Carbon-dioxide, methane, and other gases form a heat-trapping layer around the planet, acting like an extra blanket that holds in energy normally released to space. The extra warmth melts glaciers, pushes seas higher, and super-charges storms, droughts, and wildfires. Oceans soak up about 90 % of the added heat, expanding as they warm and turning more acidic, which endangers coral reefs and fisheries. Poorer communities and low-lying nations, although least responsible for emissions, feel the earliest, hardest impacts. Scientists agree—based on ice cores, tree rings, satellite data, and modern instruments—that the rise in temperature since the Industrial Revolution is human-driven and that limiting warming to 1.5 °C will require cutting global emissions roughly in half by 2030.\n\nObservation: Both outputs meet the 150-word limit. However, explain gives a more mechanism heavy response (radiative forcing, feedbacks), whereas, Summarize uses general language to describe the consequences and moral framing."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#case-2-audience-cue",
    "href": "posts/001_prompt_poker/prompt_poker.html#case-2-audience-cue",
    "title": "Prompt Poker",
    "section": "",
    "text": "Changed phrase: “a 5-year-old” -&gt; “my college roommate”\n&gt; Third prompt: Explain climate change to a 5-year-old in under 80 words.\n&gt; GPT-4o chat response 3:\n&gt; Climate change means Earth is getting hotter because people use things like cars and factories that make dirty air. The dirty air acts like a big blanket around the planet, trapping heat. This makes weather act weird — like stronger storms, really hot days, and melting ice where polar bears live. If we take better care of Earth by using clean energy and planting trees, we can help keep it safe and happy! &gt; &gt; Fourth prompt: Explain climate change to my college roommate in under 80 words.\n&gt; GPT-4o chat response 4:\n&gt; Climate change is the long-term heating of Earth’s climate system due to human activities, mainly burning fossil fuels like oil, gas, and coal. This traps heat in the atmosphere, leading to rising temperatures, stronger storms, droughts, and rising sea levels. It’s not just about the planet getting warmer — it’s about ecosystems, economies, and our future stability being at risk if we don’t shift to cleaner energy and adapt quickly.\nObservation: Depending on the audience Chat edits its diction and metaphor use. The “5-year-old” respoonse uses blankets and feelings; the “roommate” version references sea-levels, emissions, and policy fixes (more appropriate for an older audience).\n\n\n\n\nCase 2"
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#case-3-framing-bias",
    "href": "posts/001_prompt_poker/prompt_poker.html#case-3-framing-bias",
    "title": "Prompt Poker",
    "section": "",
    "text": "Changed set-up: “What causes” -&gt; “Who is to blame for”\n\nFifth prompt: What causes climate change? Give two key factors.\nGPT-4o chat response 5:\n1. Greenhouse-gas emissions from fossil fuels—Burning coal, oil, and natural gas releases CO₂, methane, and nitrous oxide that trap heat.\n2. Land-use change—Deforestation and industrial agriculture reduce carbon-sequestering vegetation and emit additional greenhouse gases.\nSixth prompt: Who is to blame for climate change? Give two key factors.\nGPT-4o chat response 6:\n1. High-income industrialized nations whose historical and current fossil-fuel use account for the majority of cumulative greenhouse-gas emissions.\n2. Large fossil-fuel corporations that continue extracting, lobbying, and advertising despite decades-old evidence of climate risk.\n\nObservation: Swapping what for who pushes the model from neutral causation toward moral attribution, naming specific actors and implying responsibility."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#key-takeaways",
    "href": "posts/001_prompt_poker/prompt_poker.html#key-takeaways",
    "title": "Prompt Poker",
    "section": "",
    "text": "Prompt verbs steer depth. Explain favors mechanism; summarize favors overview.\n\nAudience labels instantly retune register. Explaining the reader/audience removes the need to tweak the output by hand.\nFraming words can lead to bias. Using who vs. what can lead to value judgments.\nSmall edits ≠ small effects."
  },
  {
    "objectID": "posts/001_prompt_poker/prompt_poker.html#why-does-this-matter",
    "href": "posts/001_prompt_poker/prompt_poker.html#why-does-this-matter",
    "title": "Prompt Poker",
    "section": "",
    "text": "If you treat prompts as insignificant, you may accidentally change the story your model tells, undermining brand voice, skewing analysis, or injecting unintended bias. Practicing “Prompt Poker” trains you to identify and deliberately use these hidden levers!"
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "Large language models often sound so confident that even seasoned researchers will nod along, until you notice Antarctica has tigers and Mozart wrote “Bohemian Rhapsody.” To gauge how much scrutiny ChatGPT needs, I played “Two Truths & a Lie”: the model must supply three surprising facts on a topic, promising that exactly one is false. My job is to spot the hallucination and verify the truths!\n\n\n\nImage from brightsprouts.com\n\n\n\n\n\n\n\nModel: GPT-4o\n\nExperiment:\n\nAsk for three “surprising facts: two true, one false.”\n\nIdentify the claim that looks sus.\n\nFact check all three statements by searching them up on the internet. Reliable right?\n\nExpose and note which fact was actually fake news.\n\n\n\n\n\n\n\nFirst prompt: Give me three surprising facts about Mars exploration—two correct, one false but believable.\nGPT-4o chat response 1:\n1. The Curiosity rover’s wheels bear Morse-code patterns that spell “JPL.”\n2. Viking 1 carried a tiny piece of the Wright brothers’ 1903 Flyer.\n3. Ingenuity became the first aircraft to fly on another planet in 2021.\n\nFact-check:\n1. True—wheel treads do encode “JPL.”\n2. False—Ingenuity carries Wright Flyer fabric; Viking 1 did not.\n3. True—Ingenuity’s 2021 flight is historic.\n\n\n\n\nDisproved by another LLM - Google’s Gemini!\n\n\n\n\n\n\n\nSecond prompt: Three surprising facts about the human brain—two true, one false.\nGPT-4o chat response 2:\n1. The brain consumes roughly 20% of the body’s resting energy.\n2. Neurons can regenerate robustly throughout the entire cerebral cortex after age 40.\n3. The left hemisphere controls speech in about 90% of right-handed people.\n\nFact-check:\n1. True—metabolic share is ~20%.\n2. False—adult cortical neurogenesis is minimal and still debated.\n3. True—classic laterality statistic.\n\n\n\n\nTaken from the apa.org\n\n\n\n\n\n\n\nThird prompt: Three surprising facts about the Oscars—two true, one false.\nGPT-4o chat response 3:\n1. Walt Disney once received four competitive Oscars in a single night.\n2. Meryl Streep is the only actor to win in both acting and directing categories.\n3. The statuette’s official name is the “Academy Award of Merit.”\n\nFact-check:\n1. True—Disney won four in 1954.\n2. False—Streep has never won an Oscar for directing.\n3. True—“Academy Award of Merit” is the formal title.\n\n\n\n\n\nHallucinations hide in details. Dates, names, and “only ever” claims are usually where they fail/become false.\n\nPrompting for a lie doesn’t stop lying. The model happily inserts a falsehood and delivers it confidently.\n\nCritical reading is mandatory.\n\nPattern awareness helps. Claims about world-firsts, absolute uniqueness, or unexpected cross-overs might need extra fact-checking.\n\n\n\n\n\nFrom classroom handouts to official research papers, unvetted AI “facts” can slip straight into print, eroding credibility and misinforming readers. Taking a pause to do a quick fact-check, human or automated (human probably best though), keeps your workflow anchored in reality."
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#introduction",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#introduction",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "Large language models often sound so confident that even seasoned researchers will nod along, until you notice Antarctica has tigers and Mozart wrote “Bohemian Rhapsody.” To gauge how much scrutiny ChatGPT needs, I played “Two Truths & a Lie”: the model must supply three surprising facts on a topic, promising that exactly one is false. My job is to spot the hallucination and verify the truths!\n\n\n\nImage from brightsprouts.com"
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#experiment-setup",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#experiment-setup",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "Model: GPT-4o\n\nExperiment:\n\nAsk for three “surprising facts: two true, one false.”\n\nIdentify the claim that looks sus.\n\nFact check all three statements by searching them up on the internet. Reliable right?\n\nExpose and note which fact was actually fake news."
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#case-1-space-exploration",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#case-1-space-exploration",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "First prompt: Give me three surprising facts about Mars exploration—two correct, one false but believable.\nGPT-4o chat response 1:\n1. The Curiosity rover’s wheels bear Morse-code patterns that spell “JPL.”\n2. Viking 1 carried a tiny piece of the Wright brothers’ 1903 Flyer.\n3. Ingenuity became the first aircraft to fly on another planet in 2021.\n\nFact-check:\n1. True—wheel treads do encode “JPL.”\n2. False—Ingenuity carries Wright Flyer fabric; Viking 1 did not.\n3. True—Ingenuity’s 2021 flight is historic.\n\n\n\n\nDisproved by another LLM - Google’s Gemini!"
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#case-2-human-anatomy",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#case-2-human-anatomy",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "Second prompt: Three surprising facts about the human brain—two true, one false.\nGPT-4o chat response 2:\n1. The brain consumes roughly 20% of the body’s resting energy.\n2. Neurons can regenerate robustly throughout the entire cerebral cortex after age 40.\n3. The left hemisphere controls speech in about 90% of right-handed people.\n\nFact-check:\n1. True—metabolic share is ~20%.\n2. False—adult cortical neurogenesis is minimal and still debated.\n3. True—classic laterality statistic.\n\n\n\n\nTaken from the apa.org"
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#case-3-pop-culture-milestones",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#case-3-pop-culture-milestones",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "Third prompt: Three surprising facts about the Oscars—two true, one false.\nGPT-4o chat response 3:\n1. Walt Disney once received four competitive Oscars in a single night.\n2. Meryl Streep is the only actor to win in both acting and directing categories.\n3. The statuette’s official name is the “Academy Award of Merit.”\n\nFact-check:\n1. True—Disney won four in 1954.\n2. False—Streep has never won an Oscar for directing.\n3. True—“Academy Award of Merit” is the formal title."
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#key-takeaways",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#key-takeaways",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "Hallucinations hide in details. Dates, names, and “only ever” claims are usually where they fail/become false.\n\nPrompting for a lie doesn’t stop lying. The model happily inserts a falsehood and delivers it confidently.\n\nCritical reading is mandatory.\n\nPattern awareness helps. Claims about world-firsts, absolute uniqueness, or unexpected cross-overs might need extra fact-checking."
  },
  {
    "objectID": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#why-does-this-matter",
    "href": "posts/006_two_truths_and_a_hallucination/two_truths_and_a_hallucination.html#why-does-this-matter",
    "title": "Two Truths & a Hallucination",
    "section": "",
    "text": "From classroom handouts to official research papers, unvetted AI “facts” can slip straight into print, eroding credibility and misinforming readers. Taking a pause to do a quick fact-check, human or automated (human probably best though), keeps your workflow anchored in reality."
  },
  {
    "objectID": "posts/Expert Presentation/expert_blog_post.html",
    "href": "posts/Expert Presentation/expert_blog_post.html",
    "title": "Dallas",
    "section": "",
    "text": "Dallas is a large city in North Texas. Home to the Dallas Cowboys, Mavericks, and other teams. Dallas has great food, in particular, tex-mex, BBQ, and more. It is also one of the fastest growing cities currently."
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html",
    "title": "AI at the Bar",
    "section": "",
    "text": "Could an LLM stand in as junior counsel? Spotting issues, drafting arguments, and citing precedent. I gave Gemini a mock slip and fall lawsuit and watched it perform basic lawyer tasks.\n\n\n\n\nwww.martindale-avvo.com\n\n\n\n\n\n\n\nModel: Google’s Gemini 2.0 Flash\n\nExperiment:\n\nCase: Grocery-store customer slipped on spilled olive oil; claims negligence.\nJurisdiction: New York state court (tort law + CPLR).\n\n\n\n\n\n\n\nFirst prompt: List and briefly analyze every potential cause of action and defense in this fact pattern. Limit to 250 words.\n\n\nGemini chat response 1:\nOkay, let’s break down the potential legal avenues in this spilled olive oil scenario:\nPotential Causes of Action (Plaintiff - Customer):\nNegligence: The primary claim, as discussed, alleging the store failed in its duty to maintain a safe environment, leading to the slip and fall. Success hinges on proving duty, breach (notice of spill crucial), causation, and damages.   Premises Liability: This isn’t a separate cause of action in New York but rather the specific area of negligence law governing landowners’ responsibilities to those on their property. The analysis remains the same as general negligence but focuses on the store’s role as a property owner. Potential Defenses (Defendant - Grocery Store):\nLack of Notice: Arguing they had no actual or constructive knowledge of the spill and thus no opportunity to remedy it. Open and Obvious Condition: Claiming the spill was readily visible, and the customer should have avoided it, potentially leading to a finding of comparative negligence. Comparative Negligence: Asserting the customer’s own carelessness contributed to the fall (e.g., not paying attention), reducing their potential recovery under New York’s pure comparative fault rule.\nNo Causation: Arguing the slip and fall wasn’t directly caused by the olive oil (unlikely given the facts, but theoretically possible). Failure to Mitigate Damages: If applicable, arguing the customer failed to take reasonable steps to minimize their injuries. The strength of each will depend heavily on the specific details of the incident.\n\nObservation: Gemini gives a clean, readable outline that would help guide a junior associate, but it feels like a high-level sketch rather than a comprehensive checklist.\n\n\n\n\n\nSecond prompt: Draft a CPLR 3211(a)(7) motion to dismiss, 400 words, including point headings and a demand for costs\n\n\n\n\nScreenshot from Gemini Conversation\n\n\nObservation: Interestingly Gemini started to give me a response then mid way trough generation, said it couldnt provide an answer!\n\n\n\n\n\nThird prompt: Cite precedent\n\n\nGemini chat response 3:\nOkay, here’s an updated version of the CPLR 3211(a)(7) motion to dismiss, now with added citations to relevant precedent.\n\n\nfrom IPython.display import IFrame, display\nimport base64, pathlib\n\npdf_path = pathlib.Path(\"CPLR 3211(a)(7) Motion to Dismiss.pdf\")\n\ndata = base64.b64encode(pdf_path.read_bytes()).decode()\n\ndisplay(IFrame(f\"data:application/pdf;base64,{data}\", width=900, height=550))\n\n\n        \n        \n\n\n\nImportant Notes:\nAdaptation: This is a template. You’ll need to adapt it to the specifics of the case (names, dates, factual details from the Complaint). Jurisdiction: The cited cases are New York cases and apply specifically to New York law. Local Rules: Be sure to check the local rules of the specific court where the case is pending, as those rules may contain additional requirements for motion practice. I have aimed to include the most important elements of a CPLR 3211(a)(7) motion to dismiss and have cited relevant New York precedent. Remember, this is for informational purposes only and does not constitute legal advice. You should always consult with a qualified attorney to address the specifics of your situation.\n\nObservation: Gemini produced credible, real citations and avoided hallucinating new ones, but it didn’t actually summarize the holdings, so the response only half met the prompt. It’s a good first draft.\n\n\n\n\nNo new hallucinations – the phantom fake precendent case is gone (https://www.yahoo.com/news/attorney-pleads-mercy-using-ai-110052528.html)\nMissing holdings\nLooks good but is light on substance\n\n\n\n\n\n\nLLMs can draft usable first draft documents in minutes, probably great for solo attorneys or clinic students racing deadlines. However, fabricated citations or missed issues could instantly burn a case. AI is valuable for brainstorming but shouldnt be trusted without human review."
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html#introduction",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html#introduction",
    "title": "AI at the Bar",
    "section": "",
    "text": "Could an LLM stand in as junior counsel? Spotting issues, drafting arguments, and citing precedent. I gave Gemini a mock slip and fall lawsuit and watched it perform basic lawyer tasks.\n\n\n\n\nwww.martindale-avvo.com"
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html#experiment-setup",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html#experiment-setup",
    "title": "AI at the Bar",
    "section": "",
    "text": "Model: Google’s Gemini 2.0 Flash\n\nExperiment:\n\nCase: Grocery-store customer slipped on spilled olive oil; claims negligence.\nJurisdiction: New York state court (tort law + CPLR)."
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html#case-1",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html#case-1",
    "title": "AI at the Bar",
    "section": "",
    "text": "First prompt: List and briefly analyze every potential cause of action and defense in this fact pattern. Limit to 250 words.\n\n\nGemini chat response 1:\nOkay, let’s break down the potential legal avenues in this spilled olive oil scenario:\nPotential Causes of Action (Plaintiff - Customer):\nNegligence: The primary claim, as discussed, alleging the store failed in its duty to maintain a safe environment, leading to the slip and fall. Success hinges on proving duty, breach (notice of spill crucial), causation, and damages.   Premises Liability: This isn’t a separate cause of action in New York but rather the specific area of negligence law governing landowners’ responsibilities to those on their property. The analysis remains the same as general negligence but focuses on the store’s role as a property owner. Potential Defenses (Defendant - Grocery Store):\nLack of Notice: Arguing they had no actual or constructive knowledge of the spill and thus no opportunity to remedy it. Open and Obvious Condition: Claiming the spill was readily visible, and the customer should have avoided it, potentially leading to a finding of comparative negligence. Comparative Negligence: Asserting the customer’s own carelessness contributed to the fall (e.g., not paying attention), reducing their potential recovery under New York’s pure comparative fault rule.\nNo Causation: Arguing the slip and fall wasn’t directly caused by the olive oil (unlikely given the facts, but theoretically possible). Failure to Mitigate Damages: If applicable, arguing the customer failed to take reasonable steps to minimize their injuries. The strength of each will depend heavily on the specific details of the incident.\n\nObservation: Gemini gives a clean, readable outline that would help guide a junior associate, but it feels like a high-level sketch rather than a comprehensive checklist."
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html#case-2",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html#case-2",
    "title": "AI at the Bar",
    "section": "",
    "text": "Second prompt: Draft a CPLR 3211(a)(7) motion to dismiss, 400 words, including point headings and a demand for costs\n\n\n\n\nScreenshot from Gemini Conversation\n\n\nObservation: Interestingly Gemini started to give me a response then mid way trough generation, said it couldnt provide an answer!"
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html#case-3-self-citation-check",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html#case-3-self-citation-check",
    "title": "AI at the Bar",
    "section": "",
    "text": "Third prompt: Cite precedent\n\n\nGemini chat response 3:\nOkay, here’s an updated version of the CPLR 3211(a)(7) motion to dismiss, now with added citations to relevant precedent.\n\n\nfrom IPython.display import IFrame, display\nimport base64, pathlib\n\npdf_path = pathlib.Path(\"CPLR 3211(a)(7) Motion to Dismiss.pdf\")\n\ndata = base64.b64encode(pdf_path.read_bytes()).decode()\n\ndisplay(IFrame(f\"data:application/pdf;base64,{data}\", width=900, height=550))\n\n\n        \n        \n\n\n\nImportant Notes:\nAdaptation: This is a template. You’ll need to adapt it to the specifics of the case (names, dates, factual details from the Complaint). Jurisdiction: The cited cases are New York cases and apply specifically to New York law. Local Rules: Be sure to check the local rules of the specific court where the case is pending, as those rules may contain additional requirements for motion practice. I have aimed to include the most important elements of a CPLR 3211(a)(7) motion to dismiss and have cited relevant New York precedent. Remember, this is for informational purposes only and does not constitute legal advice. You should always consult with a qualified attorney to address the specifics of your situation.\n\nObservation: Gemini produced credible, real citations and avoided hallucinating new ones, but it didn’t actually summarize the holdings, so the response only half met the prompt. It’s a good first draft.\n\n\n\n\nNo new hallucinations – the phantom fake precendent case is gone (https://www.yahoo.com/news/attorney-pleads-mercy-using-ai-110052528.html)\nMissing holdings\nLooks good but is light on substance"
  },
  {
    "objectID": "posts/011_ai_at_the_bar/ai_at_the_bar.html#why-does-this-matter",
    "href": "posts/011_ai_at_the_bar/ai_at_the_bar.html#why-does-this-matter",
    "title": "AI at the Bar",
    "section": "",
    "text": "LLMs can draft usable first draft documents in minutes, probably great for solo attorneys or clinic students racing deadlines. However, fabricated citations or missed issues could instantly burn a case. AI is valuable for brainstorming but shouldnt be trusted without human review."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]